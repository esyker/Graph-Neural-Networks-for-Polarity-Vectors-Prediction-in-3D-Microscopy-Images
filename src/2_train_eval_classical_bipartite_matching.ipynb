{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374070c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from typing import List, Dict, Tuple\n",
    "import io\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "import datetime\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import csv\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.transforms\n",
    "import torch_geometric.datasets\n",
    "import torch_geometric.nn\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', module='sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_variables import *\n",
    "from utils_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f73a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_output_dir = \"./results\"\n",
    "if not os.path.exists(results_output_dir):\n",
    "    os.makedirs(results_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd99e9a",
   "metadata": {},
   "source": [
    "# Bipartite Matching Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_params_bipartite():\n",
    "    data_types = [\n",
    "                #\"Real\", \n",
    "                \"Real_automatic\",\n",
    "                #\"../data/synthetic_algo_100_points\",\n",
    "                #\"../data/synthetic_algo_200_points\",\n",
    "                #\"../data/synthetic_algo_300_points\",\n",
    "                #\"../data/synthetic_algo_400_points\",\n",
    "                #\"../data/synthetic_algo_500_points\",\n",
    "                #\"../data/synthetic_algo_600_points\",\n",
    "                #\"../data/synthetic_algo_700_points\",\n",
    "                #\"../data/synthetic_algo_800_points\",\n",
    "                #\"../data/synthetic_algo_900_points\",\n",
    "                #\"../data/synthetic_algo_1000_points\"\n",
    "    ]\n",
    "\n",
    "    combinations = {\n",
    "        \"data_type_train\": data_types,\n",
    "        \"model_type\":[\n",
    "                        \"Hopcroft_Karp\",\n",
    "                        \"Minimum Weight\"\n",
    "        ],\n",
    "        \"knn_inter_nodes\":[\n",
    "                            #\"min\",\n",
    "                            #7,\n",
    "                            10\n",
    "        ],\n",
    "        \"knn_inter_nodes_max\": [7],\n",
    "       \"knn_intra_nodes\":[0],\n",
    "        \"normalize\":[\n",
    "                    False, \n",
    "                     #True\n",
    "                    ],\n",
    "        \"node_feats\":[[\n",
    "            'Y', \n",
    "            'X', \n",
    "            'Z', \n",
    "            'node_type', \n",
    "            'ID'\n",
    "        ]],\n",
    "        \"edge_feats\":[[\n",
    "    'source',\n",
    "    'target',\n",
    "     'edge_label',\n",
    "     'delta_x',\n",
    "     'delta_y',\n",
    "     'delta_z',\n",
    "     'weight',\n",
    "     'edge_type',\n",
    "     'angle_orientation_theta',\n",
    "     'angle_orientation_phi']],\n",
    "    }\n",
    "\n",
    "\n",
    "    job_parameters = []\n",
    "\n",
    "\n",
    "    # Generate all possible combinations of the dictionary values\n",
    "    for values in itertools.product(*combinations.values()):\n",
    "        # Generate a dictionary for the combination of values\n",
    "        job_dict = dict(zip(combinations.keys(), values))\n",
    "        job_dict[\"scale_features\"] = True if \"Real\" in job_dict[\"data_type_train\"] else False\n",
    "        job_parameters.append(job_dict)\n",
    "    \n",
    "    return job_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4741f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_list_bipartite(job_parameters, debug = False):\n",
    "    #build dataframes\n",
    "    graph_list_dict_bipartite = {}\n",
    "\n",
    "    for params in tqdm(job_parameters):\n",
    "\n",
    "        params_list = [params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                        params[\"knn_inter_nodes_max\"],params[\"normalize\"],\n",
    "                                        params[\"scale_features\"], str(params[\"node_feats\"]), str(params[\"edge_feats\"])]\n",
    "        params_list = [str(param_) for param_ in params_list]\n",
    "        graph_key = \"_\".join(params_list)\n",
    "\n",
    "        if graph_key not in graph_list_dict_bipartite:\n",
    "            graph_list = get_graph_list(params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                            params[\"knn_inter_nodes_max\"], normalize = params[\"normalize\"],\n",
    "                                            scale_feats = params[\"scale_features\"],\n",
    "                                            node_feats = params[\"node_feats\"], edge_feats = params[\"edge_feats\"],\n",
    "                                            shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "            graph_list_dict_bipartite[graph_key] = graph_list\n",
    "\n",
    "    return graph_list_dict_bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f2382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bipartite(graph_list_dict_bipartite, job_parameters, debug = False, make_plots = True):\n",
    "    results_list_mf = []\n",
    "\n",
    "    for params in job_parameters:\n",
    "        print(\"\\n\\n\\n####################################\")\n",
    "        metrics_list_bipartite = []\n",
    "\n",
    "        params_list = [params[\"data_type_train\"], params[\"knn_inter_nodes\"], params[\"knn_intra_nodes\"], \n",
    "                                        params[\"knn_inter_nodes_max\"],params[\"normalize\"],\n",
    "                                        params[\"scale_features\"], str(params[\"node_feats\"]), str(params[\"edge_feats\"])]\n",
    "        params_list = [str(param_) for param_ in params_list]\n",
    "        graph_key = \"_\".join(params_list)\n",
    "        graph_list = graph_list_dict_bipartite[graph_key]\n",
    "\n",
    "        for graph in graph_list:\n",
    "            graph_id, nodes_df, edges_df, edges_df_knn, k_intra, k_inter = graph.graph_id, graph.nodes_df, graph.edges_df, graph.edges_df_knn, graph.k_intra, graph.k_inter\n",
    "            print(\"Graph_ID:\",graph_id,\"K_INTRA:\",k_intra, \"K_INTER:\",k_inter)\n",
    "\n",
    "            edges_df_bipartite_graph = edges_df_knn.copy()\n",
    "            nx_G_knn = nx_build_graph(nodes_df, edges_df_bipartite_graph)\n",
    "\n",
    "            model_type = params[\"model_type\"]\n",
    "\n",
    "            #get the bipartite edges_list\n",
    "            if(model_type==\"Hopcroft_Karp\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.maximum_matching(nx_G_knn)\n",
    "            elif(model_type==\"Eppstein\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.eppstein_matching(nx_G_knn)\n",
    "            elif(model_type==\"Minimum Weight\"):\n",
    "                nx_bipartite_edges_list = nx.bipartite.minimum_weight_full_matching(nx_G_knn)\n",
    "            else:\n",
    "                raise ValueError(\"Model not implemented!\")\n",
    "\n",
    "            #convert to Dataframe\n",
    "            edges_df_bipartite = nx_convert_dict_to_edges_df(nx_bipartite_edges_list)\n",
    "            #apply the pred labels to edges_df_bipartite, taking as input the edges_df_knn\n",
    "            edges_df_bipartite[\"edge_label\"] = 1\n",
    "            edges_df_bipartite = apply_edges_df_label(edges_df_bipartite, edges_df_knn)\n",
    "\n",
    "            metrics_bipartite, edge_labels_string_bipartite = eval_edges_df(edges_df, edges_df_bipartite)\n",
    "            metrics_list_bipartite.append(metrics_bipartite)\n",
    "\n",
    "            print(json.dumps(metrics_bipartite, indent = 1))\n",
    "\n",
    "            #Save results to file\n",
    "            bipartite_results_array = pred_df_to_csv(edges_df_bipartite, graph.nodes_df_original)\n",
    "            output_file_dir =  results_output_dir+\"/\"+params[\"data_type_train\"]+\"_\"+params[\"model_type\"]+\"_\" +\\\n",
    "                                    str(params[\"knn_inter_nodes\"])+\"_\"+str(params[\"knn_intra_nodes\"])+\"/\"\n",
    "            if not os.path.exists(output_file_dir):\n",
    "                os.makedirs(output_file_dir)\n",
    "            output_file_path = os.path.join(output_file_dir, graph.graph_id)\n",
    "            array_to_csv(bipartite_results_array, output_file_path)\n",
    "\n",
    "            if(make_plots):\n",
    "                fig_bipartite = df_make_plot(nodes_df, edges_df_bipartite, edge_labels_string_bipartite, \"Bipartite\")\n",
    "                plt.show()\n",
    "        \n",
    "        ####################################\n",
    "        ### Aggregate Metrics at the end  ##\n",
    "        ####################################\n",
    "\n",
    "        metrics_bipartite_aggregated = aggregate_metrics(metrics_list_bipartite)\n",
    "        print(json.dumps(metrics_bipartite_aggregated,indent = 1))\n",
    "\n",
    "        result_bipartite = {}\n",
    "        result_bipartite[\"aggregated_metrics\"] = metrics_bipartite_aggregated\n",
    "        params[\"angle_features\"] = \"NA\"\n",
    "        params[\"constraints\"] = \"NA\"\n",
    "        result_bipartite[\"job_parameters\"] = params\n",
    "        results_list_mf.append(result_bipartite)\n",
    "    return results_list_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19088fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_bipartite(results_list_bipartite):\n",
    "    plot_df_mf = plot_table(results_list_bipartite, metrics_dict_entries = [None])\n",
    "    plot_df_mf = plot_df_mf.sort_values(by=[\"K Inter\", 'Algorithm', 'Data Train', 'Data Test'])\n",
    "    display(plot_df_mf)\n",
    "    #plot_df_mf = plot_df_mf.drop([\"Data Train\", \"Data Test\", \"Scale\"], axis=1)\n",
    "    plot_df_mf = plot_df_mf.drop([\"Data Test\", \"Scale\"], axis=1)\n",
    "    display(plot_df_mf)\n",
    "    print(plot_df_to_latex(plot_df_mf))\n",
    "    return plot_df_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c93120",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_parameters_bipartite = get_job_params_bipartite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_list_dict_bipartite = get_graph_list_bipartite(job_parameters_bipartite, debug = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_csv(array : np.array, csv_path : str, separator = \",\", columns_order=['YN', 'XN', 'YG', 'XG', 'ZN', 'ZG']):\n",
    "    with open(csv_path, 'w') as fp:\n",
    "        for i in range(len(array)):\n",
    "            row_array = array[i]\n",
    "            array_dict = {}\n",
    "            array_dict[\"XN\"], array_dict[\"YN\"], array_dict[\"ZN\"], array_dict[\"XG\"], array_dict[\"YG\"], array_dict[\"ZG\"] = row_array[0], row_array[1], row_array[2], row_array[3], row_array[4], row_array[5]\n",
    "            new_array = [array_dict[col] for col in columns_order]\n",
    "            row = separator.join(str(v) for v in new_array)\n",
    "            if(i!=(len(array)-1)):#only write \\n up to the line before the last line\n",
    "                row+=\"\\n\"\n",
    "            fp.write(row)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66444ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_bipartite = train_bipartite(graph_list_dict_bipartite, job_parameters_bipartite, debug = True, make_plots = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = plot_results_bipartite(results_list_bipartite) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b039b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_final_format(output_df):\n",
    "    output_df = output_df.drop([\"Node Feat.\", \"Normalize\", \"K Intra\",  \"TP Percent\",\"TP Total Count\",\"TP\",\"FP\",\"TN\",\"FN\"], axis = 1)\n",
    "    output_df = output_df.rename(columns={\"K Inter\": \"K\", \"Edge Feat.\":\"Angles\"})\n",
    "    if(\"Angles\" in output_df.columns):\n",
    "        output_df[\"Angles\"] = output_df[\"Angles\"].apply(lambda x: all(\"angle\" not in item for item in x))\n",
    "    return output_df\n",
    "\n",
    "final_output_df = convert_to_final_format(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a60ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_df[\"Data Train\"] = final_output_df[\"Data Train\"].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "columns_to_drop = [\"K\", \"ROC AUC Score\", \"Constraints\", \"Angles\"]\n",
    "columns_to_drop = [col for col in columns_to_drop if col in final_output_df.columns.tolist()]\n",
    "final_output_df= final_output_df.drop(columns_to_drop,axis=1)\n",
    "\n",
    "final_output_df = final_output_df[[\"Data Train\", \"Algorithm\",\"Accuracy\",\"TPR\", \"FPR\", \"Precision\",\"F1-Score\"]]\n",
    "final_output_df = final_output_df.sort_values(by=['Data Train'])\n",
    "print(plot_df_to_latex(final_output_df))\n",
    "final_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8d5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
