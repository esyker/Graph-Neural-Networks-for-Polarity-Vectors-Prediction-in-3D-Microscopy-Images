{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a421f-48f4-462f-a0fe-e1a9bcb643f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from utils_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287099a-c4c5-49a9-b775-be04895c3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "### Define int encodings for string variables #####\n",
    "###################################################\n",
    "\n",
    "#nodes type encodings\n",
    "nodes_type_int_encodings = {\n",
    "    \"nuclei\":0,\n",
    "    \"golgi\":1\n",
    "}\n",
    "\n",
    "reversed_nodes_type_int_encodings = {v: k for k, v in nodes_type_int_encodings.items()}\n",
    "\n",
    "#edges type encodings\n",
    "edges_type_int_encodings = {\n",
    "    \"nuclei-nuclei\":0,\n",
    "    \"golgi-golgi\":1,\n",
    "    \"golgi-nuclei\":2,\n",
    "    \"nuclei-golgi\":3\n",
    "}\n",
    "\n",
    "reversed_edges_type_int_encodings = {v: k for k, v in edges_type_int_encodings.items()}\n",
    "\n",
    "def nx_convert_edges_df_to_list(edges_df):\n",
    "    \"\"\"\n",
    "    Converts a Pandas DataFrame of edges to a list of edges.\n",
    "\n",
    "    Args:\n",
    "    edges_df: A Pandas DataFrame of edges.\n",
    "\n",
    "    Returns:\n",
    "    A list of edges.\n",
    "    \"\"\"\n",
    "\n",
    "    edges_list = []\n",
    "    for i in range(len(edges_df)):\n",
    "        edge = [edges_df.loc[i, \"source\"], edges_df.loc[i, \"target\"]]\n",
    "        edge_attrs = {}\n",
    "        for col in edges_df.columns:\n",
    "            if col not in [\"source\", \"target\"]:\n",
    "                edge_attrs[col] = edges_df.loc[i, col] \n",
    "        edge.append(edge_attrs)\n",
    "        edges_list.append(edge)\n",
    "    return edges_list\n",
    "\n",
    "def nx_convert_nodes_df_to_list(nodes_df):\n",
    "    nodes_list = []\n",
    "    for index, row in nodes_df.iterrows():\n",
    "        node_info = (row[\"ID\"],{\n",
    "            \"Y\": row[\"Y\"],\n",
    "            \"X\": row[\"X\"],\n",
    "            \"Z\": row[\"Z\"],\n",
    "            \"node_type\": row[\"node_type\"]\n",
    "        })\n",
    "        nodes_list.append(node_info)\n",
    "    return nodes_list\n",
    "    \n",
    "def load_df_from_csv(gt_vectors_csv: str, column_names=['YN', 'XN', 'YG', 'XG', 'ZN', 'ZG'],\n",
    "                     nuclei_columns=['YN', 'XN', 'ZN'],\n",
    "                     golgi_columns=['YG', 'XG', 'ZG'],\n",
    "                     nodes_type_int_encodings=nodes_type_int_encodings,\n",
    "                    edges_type_int_encodings = edges_type_int_encodings):\n",
    "    if(\"automatic\" in gt_vectors_csv and \"results\" not in gt_vectors_csv):\n",
    "        df = pd.read_csv(gt_vectors_csv, delimiter=\",\")\n",
    "        df[\"node_type\"] = df[\"node_type\"].apply(lambda x : nodes_type_int_encodings[x])\n",
    "        nodes_df = df.copy()\n",
    "        edges_df = pd.DataFrame(columns=['source', 'target', \"edge_type\"])#empty\n",
    "    else:\n",
    "        df = pd.read_csv(gt_vectors_csv, delimiter=\",\", header=None)\n",
    "        df.columns = column_names\n",
    "\n",
    "        # Split the DataFrame into two\n",
    "        nuclei_df = df[nuclei_columns].copy().reset_index(drop=True)\n",
    "        nuclei_df[\"node_type\"] = nodes_type_int_encodings['nuclei']\n",
    "        nuclei_df.rename(columns={'YN': 'Y', 'XN': 'X', 'ZN': 'Z'}, inplace=True)  # Rename nuclei columns\n",
    "\n",
    "        golgi_df = df[golgi_columns].copy().reset_index(drop=True)\n",
    "        golgi_df[\"node_type\"] = nodes_type_int_encodings['golgi']\n",
    "        golgi_df.rename(columns={'YG': 'Y', 'XG': 'X', 'ZG': 'Z'}, inplace=True)  # Rename golgi columns\n",
    "\n",
    "        # Set the 'ID'\n",
    "        golgi_df[\"ID\"] = range(len(nuclei_df), len(nuclei_df) + len(golgi_df))\n",
    "        nuclei_df[\"ID\"] = range(len(nuclei_df))\n",
    "\n",
    "        # Concatenate the two DataFrames into 'nodes_df'\n",
    "        nodes_df = pd.concat([nuclei_df, golgi_df]).reset_index(drop=True)\n",
    "        nodes_df[\"X\"] = nodes_df[\"X\"].apply(lambda x: x - 1)\n",
    "        nodes_df[\"Y\"] = nodes_df[\"Y\"].apply(lambda y: y - 1)\n",
    "        nodes_df[\"Z\"] = nodes_df[\"Z\"].apply(lambda z: z - 1)\n",
    "\n",
    "        # Create edges between nuclei and golgi based on nodes in the same line\n",
    "        edges_df = pd.DataFrame({'source': nuclei_df['ID'], 'target': golgi_df['ID']})        \n",
    "        \n",
    "    return df, nodes_df, edges_df\n",
    "\n",
    "def add_legend_plot(ax, plot_styles):\n",
    "    # Create custom legend handles and labels based on plot_styles\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "\n",
    "    #Add Edge Legends\n",
    "    for label, style in plot_styles.items():\n",
    "        if isinstance(style, dict) and \"dashed\" in style:\n",
    "            color = style[\"color\"]\n",
    "            dashed = style.get(\"dashed\", False)\n",
    "            alpha = style[\"alpha\"]\n",
    "            linestyle = \"--\" if dashed else \"-\"\n",
    "            legend_handles.append(matplotlib.lines.Line2D([0], [0], color=color, linewidth=2, linestyle=linestyle, label=label, alpha = alpha))\n",
    "            legend_labels.append(label.upper() + \" Edge\")\n",
    "\n",
    "    # Add node legends\n",
    "    legend_handles.append(matplotlib.lines.Line2D([0], [0], marker=plot_styles[\"nuclei\"][\"marker\"], color=\"w\", alpha = plot_styles[\"nuclei\"][\"alpha\"],\n",
    "                                    label=\"Nuclei\", markerfacecolor=plot_styles[\"nuclei\"][\"color\"], markersize=10))\n",
    "    legend_labels.append(\"Nuclei\")\n",
    "    legend_handles.append(matplotlib.lines.Line2D([0], [0], marker=plot_styles[\"golgi\"][\"marker\"], color=\"w\", alpha = plot_styles[\"golgi\"][\"alpha\"],\n",
    "                                    label=\"Golgi\", markerfacecolor=plot_styles[\"golgi\"][\"color\"], markersize=10))\n",
    "    legend_labels.append(\"Golgi\")\n",
    "\n",
    "    legend = ax.legend(legend_handles, legend_labels, loc=\"upper right\", fontsize=\"small\", ncol=2)\n",
    "    \n",
    "    return legend\n",
    "\n",
    "def df_make_plot(ax, nodes_df, edges_df, edge_labels, title, plot_styles = {\n",
    "                \"nuclei\":{\"marker\":\"o\",\"color\":\"red\", \"alpha\":0.3},\n",
    "                \"golgi\":{\"marker\":\"o\",\"color\":\"green\", \"alpha\":0.3},\n",
    "                \"\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                #\"tp\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                #\"fp\": {\"color\": \"yellow\", \"dashed\": False, \"alpha\":1},\n",
    "                #\"tn\": None,\n",
    "                #\"fn\": {\"color\": \"blue\",  \"dashed\": True, \"alpha\":1}\n",
    "            }, add_legends=True):\n",
    "    node_list = nx_convert_nodes_df_to_list(nodes_df)\n",
    "    edge_list = nx_convert_edges_df_to_list(edges_df)\n",
    "\n",
    "    GraphInfo.plot_graph_nx_matplotlib(node_list, edge_list, edge_labels, ax, dims = 3, plot_styles = plot_styles, reversed_nodes_type_int_encodings = reversed_nodes_type_int_encodings)\n",
    "    if(title):\n",
    "        plt.title(title, fontsize = 15)\n",
    "    \n",
    "    #Legends\n",
    "    if(add_legends):\n",
    "        add_legend_plot(ax, plot_styles)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76704a10-37e9-4642-9f86-7c901f20708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphInfo:\n",
    "    def __init__(self, \n",
    "                 raw_df, nodes_df_original,\n",
    "                 nodes_df, edges_df, edges_df_knn,\n",
    "                 graph_id = None, k_inter = None, k_intra = None, node_feats = \"all\",\n",
    "                edge_feats = \"all\"):\n",
    "        \n",
    "        self.graph_id = graph_id\n",
    "        self.k_inter = k_inter\n",
    "        self.k_intra = k_intra\n",
    "        \n",
    "        self.raw_df = raw_df\n",
    "        \n",
    "        self.nodes_df_original = nodes_df_original\n",
    "        self.nodes_df = nodes_df\n",
    "        \n",
    "        self.edges_df = edges_df\n",
    "        self.edges_df_knn = edges_df_knn\n",
    "        \n",
    "        self.concat_nodes_edges_df = apply_concat_nodes_edges_df(self.nodes_df, self.edges_df_knn)\n",
    "        \n",
    "        node_feats_cols_to_remove = [col for col in list(self.nodes_df.columns) if col not in node_feats]\n",
    "        node_feats_cols_to_remove = list(set([\"ID\"]+node_feats_cols_to_remove))\n",
    "        \n",
    "        edge_feats_cols_to_remove = [col for col in list(self.edges_df.columns) if col not in edge_feats]\n",
    "        edge_feats_cols_to_remove = list(set([\"source\",\"target\",\"edge_label\"]+edge_feats_cols_to_remove))\n",
    "        \n",
    "        self.pyg_graph = pyg_load_graph_from_df(self.nodes_df, self.edges_df_knn, to_undirected = False, graph_type = \"homo\",\n",
    "                             node_feats_cols_to_remove = node_feats_cols_to_remove, edge_feats_cols_to_remove = edge_feats_cols_to_remove,\n",
    "                            encoder = pyg_IdentityEncoder())\n",
    "            \n",
    "        self.pyg_graph_edge_list, self.pyg_graph_true_labels, self.edge_list, self.edge_list_knn = [], np.array([]), [], []\n",
    "        self.pyg_graph_edge_list = self.edge_index_to_edge_list(self.pyg_graph.edge_index)\n",
    "        self.pyg_graph_true_labels = self.pyg_graph.edge_label.detach().cpu().numpy()\n",
    "        self.edge_list = nx_convert_edges_df_to_list(self.edges_df)\n",
    "        self.edge_list_knn = nx_convert_edges_df_to_list(self.edges_df_knn)\n",
    "        \n",
    "        self.node_list = nx_convert_nodes_df_to_list(self.nodes_df)\n",
    "        \n",
    "        #Commented because of empty edges_df for automatic graphs\n",
    "        self.sklearn_graph = {}\n",
    "        self.sklearn_graph[\"X_TRUE\"], self.sklearn_graph[\"Y_TRUE\"], self.sklearn_graph[\"X_KNN\"], self.sklearn_graph[\"Y_KNN\"] = sklearn_dataset_to_pytorch(self, shuffle = True)\n",
    "        \n",
    "        if node_feats != \"all\":\n",
    "            self.nodes_df = self.nodes_df[node_feats]\n",
    "        if edge_feats != \"all\":\n",
    "            self.edges_df, self.edges_df_knn = self.edges_df[edge_feats] , self.edges_df_knn[edge_feats]\n",
    "            \n",
    "    @staticmethod\n",
    "    def edge_index_to_edge_list(edge_index):\n",
    "        \"\"\"\n",
    "        Convert PyTorch Geometric edge_index tensor to NetworkX edge_list format.\n",
    "\n",
    "        Args:\n",
    "            edge_index (torch.Tensor): Edge index tensor (2 x num_edges) in PyTorch Geometric format.\n",
    "            num_nodes (int): Number of nodes in the graph.\n",
    "\n",
    "        Returns:\n",
    "            list: List of edges in NetworkX edge_list format.\n",
    "        \"\"\"\n",
    "        edge_list = edge_index.t().tolist()  # Transpose edge_index and convert to list\n",
    "        return edge_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def edge_list_to_edge_df(edge_list):\n",
    "        data_list = []\n",
    "        for edge in edge_list:\n",
    "            data_list.append({\"source\":edge[0], \"target\":edge[1], \"edge_label\":1})\n",
    "        edges_df = pd.DataFrame(data_list) \n",
    "        return edges_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_edge_pred_to_label(true, pred):\n",
    "        label_mapping = {\n",
    "            (1, 1): \"tp\",\n",
    "            (1, 0): \"fn\",\n",
    "            (0, 1): \"fp\",\n",
    "            (0, 0): \"tn\"\n",
    "        }\n",
    "        return label_mapping[(true, pred)]\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_edge_preds_to_labels(true_labels, pred_labels):\n",
    "        \"\"\"\n",
    "        Converts edge predicted output (0 or 1) to tp,fp,tn,fn\n",
    "\n",
    "        Args:\n",
    "            pred_labels (list): List of predicted edge labels (0 or 1) corresponding to each edge.\n",
    "            true_labels (list): List of true edge labels (0 or 1) corresponding to each edge.\n",
    "\n",
    "        Returns:\n",
    "            pred_labels_list (list) : List of strings with \"tp\", \"fp\", \"tn\", \"fn\"\n",
    "        \"\"\"\n",
    "        pred_labels_list = []\n",
    "        \n",
    "        for i, (true, pred) in enumerate(zip(true_labels, pred_labels)):\n",
    "            \n",
    "            label = GraphInfo.convert_edge_pred_to_label(true, pred)\n",
    "            pred_labels_list.append(label)\n",
    "        \n",
    "        return pred_labels_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_graph_nx_matplotlib(node_list, edge_list, edge_labels, ax, dims = 2, \n",
    "        plot_edges = True, \n",
    "        plot_styles = {\n",
    "            \"nuclei\":{\"marker\":\"o\",\"color\":\"red\", \"alpha\":0.3},\n",
    "            \"golgi\":{\"marker\":\"o\",\"color\":\"green\", \"alpha\":0.3},\n",
    "            \"edge\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "            #\"tp\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "            #\"fp\": {\"color\": \"yellow\", \"dashed\": False, \"alpha\":1},\n",
    "            #\"tn\": None,\n",
    "            #\"fn\": {\"color\": \"blue\",  \"dashed\": True, \"alpha\":1}\n",
    "        }, reversed_nodes_type_int_encodings = reversed_nodes_type_int_encodings):\n",
    "        \n",
    "        assert (len(edge_list)==len(edge_labels))\n",
    "        dims_allowed_values = [2,3]\n",
    "        if dims not in dims_allowed_values:\n",
    "            raise ValueError(\"Wrong dims! Allowed values\", str(dims_allowed_values))\n",
    "        \n",
    "        node_pos = {}\n",
    "        # Draw nodes\n",
    "        for node in node_list:\n",
    "            node_id = node[0]\n",
    "            node_info = node[1]\n",
    "            node_type = reversed_nodes_type_int_encodings[node_info[\"node_type\"]]\n",
    "            node_color = plot_styles[node_type][\"color\"]#node_info[\"color\"]\n",
    "            node_alpha = plot_styles[node_type][\"alpha\"]\n",
    "            marker = plot_styles[node_type][\"marker\"]\n",
    "            node_size = 30#node_info[\"size\"]\n",
    "            pos = (node_info[\"X\"], node_info[\"Y\"], node_info[\"Z\"])#node_info[\"coordinates\"]#node_pos_list[node_id]\n",
    "            node_pos[node_id] = pos\n",
    "            \n",
    "            if(dims ==2):\n",
    "                ax.scatter(pos[0], pos[1], s=node_size, c=node_color, marker = marker, alpha = node_alpha)\n",
    "            else:\n",
    "                ax.scatter3D(pos[0], pos[1], pos[2], s=node_size, c=node_color, marker = marker, alpha = node_alpha)\n",
    "        \n",
    "        if plot_edges:\n",
    "            linewidth = 1\n",
    "            alpha = 1\n",
    "            for i in range(len(edge_list)):\n",
    "                u = edge_list[i][0]\n",
    "                v = edge_list[i][1]\n",
    "                edge_label = edge_labels[i]\n",
    "                edge_style = plot_styles[edge_label]\n",
    "\n",
    "\n",
    "                if(edge_style!=None):\n",
    "                    color = edge_style[\"color\"]\n",
    "                    dashed = edge_style[\"dashed\"]\n",
    "                    alpha = edge_style[\"alpha\"]\n",
    "\n",
    "                    # Draw arrows\n",
    "                    if dashed:\n",
    "                        line_style = \"--\"\n",
    "                    else:\n",
    "                        line_style = \"-\"\n",
    "\n",
    "                    if dims == 2:\n",
    "                        line_kwargs = {\n",
    "                            \"linewidth\": linewidth,\n",
    "                            \"color\": color,\n",
    "                            \"alpha\": alpha,\n",
    "                            \"linestyle\": line_style                    \n",
    "                        }\n",
    "                        ax.plot([node_pos[u][0], node_pos[v][0]],\n",
    "                                [node_pos[u][1], node_pos[v][1]], **line_kwargs)\n",
    "                    else:\n",
    "                        line_kwargs = {\n",
    "                            \"linewidth\": linewidth,\n",
    "                            \"color\": color,\n",
    "                            \"alpha\": alpha,\n",
    "                            \"linestyle\": line_style\n",
    "                        }\n",
    "                        ax.plot([node_pos[u][0], node_pos[v][0]],\n",
    "                                [node_pos[u][1], node_pos[v][1]],\n",
    "                                [node_pos[u][2], node_pos[v][2]], **line_kwargs)\n",
    "\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        if(dims==3):\n",
    "            ax.set_zlabel(\"Z\", labelpad=-2)  # Adjust this value as needed, default is 5\n",
    "        return ax\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_graph_plot(node_list, edge_list, edge_labels, plot_styles, dims = 2,\n",
    "                        title = \"\", figax = None, figsize = (6,4), plot_edges = True):\n",
    "\n",
    "        #True Graph\n",
    "        graph_fig = figax\n",
    "        if(not graph_fig):\n",
    "            graph_fig = plt.figure(figsize=figsize)\n",
    "        plt.title(title)\n",
    "        \n",
    "        #G_nx = build_graph_nx(node_list, edge_list)\n",
    "        \n",
    "        graph_fig = GraphInfo.plot_graph_nx_matplotlib(node_list, edge_list, edge_labels,  \n",
    "                                                       graph_fig, dims = dims, plot_styles = plot_styles, \n",
    "                                                       plot_edges = plot_edges)\n",
    "        \n",
    "        return graph_fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize_nodes_df(df, plot_styles = {\n",
    "            \"nuclei\":{\"marker\":\"o\",\"color\":\"red\", \"alpha\":0.3},\n",
    "            \"golgi\":{\"marker\":\"o\",\"color\":\"green\", \"alpha\":0.3},\n",
    "            \"tp\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "            \"fp\": {\"color\": \"yellow\", \"dashed\": False, \"alpha\":1},\n",
    "            \"tn\": None,\n",
    "            \"fn\": {\"color\": \"blue\",  \"dashed\": True, \"alpha\":1}\n",
    "        }, figsize = (6,4)):\n",
    "        \n",
    "        # Plot\n",
    "        fig = plt.figure(figsize=figsize,dpi=250)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        ax.grid(False)\n",
    "        ax.xaxis.pane.fill = ax.yaxis.pane.fill = ax.zaxis.pane.fill = False\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.set_zlabel(\"Z\")\n",
    "    \n",
    "        for idx, row in df.iterrows():\n",
    "            x, y, z = row['X'], row['Y'], row['Z']\n",
    "            node_type = reversed_nodes_type_int_encodings[row[\"node_type\"]]\n",
    "            node_color = plot_styles[node_type][\"color\"]\n",
    "            node_alpha = plot_styles[node_type][\"alpha\"]\n",
    "            marker = plot_styles[node_type][\"marker\"]\n",
    "            ax.scatter3D(x, y, z, s=30, c=node_color, marker = marker, alpha = node_alpha)\n",
    "        \n",
    "        return ax "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d7c21",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Group results across different trials\n",
    "\"\"\"\n",
    "\n",
    "def plot_results_dl(results_list_pytorch):\n",
    "    plot_df_pytorch = plot_table(results_list_pytorch, metrics_dict_entries = [[\"@best\",\"metrics\"],[\"@best\",\"@constraints\",\"metrics\"],\n",
    "                                                                               [\"@constraints\",\"metrics\"], [\"@constraints_opt\",\"metrics\"]])\n",
    "    plot_df_pytorch = plot_df_pytorch.sort_values(by=[\"Algorithm\", \"Normalize\", \"K Inter\", 'Data Train', 'Data Test','Constraints'])\n",
    "    #plot_df_pytorch = plot_df_pytorch.drop([\"Data Train\", \"Data Test\"], axis=1)\n",
    "    return plot_df_pytorch\n",
    "\n",
    "def convert_to_final_format(output_df):\n",
    "    output_df = output_df.drop([\"Node Feat.\", \"Scale\", \"Normalize\", \"K Intra\", \"K Inter\", \"TP Percent\",\"TP Total Count\",\"TP\",\"FP\",\"TN\",\"FN\"], axis = 1)\n",
    "    output_df = output_df.rename(columns={\"Edge Feat.\":\"Angles\"})\n",
    "    output_df[\"Angles\"] = output_df[\"Angles\"].apply(lambda x: any(\"angle\" in item for item in x))\n",
    "    return output_df\n",
    "\n",
    "# Load Data\n",
    "def load_results_data(results_folder):\n",
    "    folders = [\n",
    "            os.path.join(results_folder,\"trial1\"), \n",
    "            os.path.join(results_folder,\"trial2\"), \n",
    "            os.path.join(results_folder,\"trial3\")\n",
    "    ]\n",
    "    subfolders = [el for el in os.listdir(folders[0]) if \"constraints\" not in el]\n",
    "\n",
    "\n",
    "    folders_dict = {}\n",
    "    for subfolder in subfolders:\n",
    "        if subfolder not in folders_dict:\n",
    "            folders_dict[subfolder] = {}\n",
    "        for folder in folders:\n",
    "            folders_dict[subfolder][folder] = {}\n",
    "            subfolder_path = os.path.join(folder,subfolder)\n",
    "\n",
    "            with open(os.path.join(subfolder_path, \"params.json\"), 'r') as file:\n",
    "                params = json.load(file)\n",
    "\n",
    "            files_info = {\"graphs\":[os.path.join(folder, el) for el in os.listdir(subfolder_path) if el!=\"params.json\"], \"params\": params} \n",
    "            folders_dict[subfolder][folder] = files_info\n",
    "\n",
    "    df_rows = []\n",
    "\n",
    "    for subfolder in folders_dict:\n",
    "        for folder in folders_dict[subfolder]:\n",
    "            el = folders_dict[subfolder][folder]\n",
    "            job_parameters = el[\"params\"][\"job_parameters\"]\n",
    "            graphs = el[\"graphs\"]\n",
    "            metrics = el[\"params\"]\n",
    "            df_rows.append(metrics)\n",
    "\n",
    "    output_df = plot_results_dl(df_rows)\n",
    "\n",
    "    output_df = convert_to_final_format(output_df)\n",
    "    numeric_cols = [\"ROC AUC Score\",\t\"Accuracy\",\t\"Precision\",\t\"TPR\", \"FPR\"\t,\"F1-Score\"]\n",
    "    output_df[numeric_cols] = output_df[numeric_cols].astype(float)\n",
    "    output_df = output_df.reset_index(drop=True)\n",
    "    return output_df\n",
    "\n",
    "#With Edge Feats and With Node Feats\n",
    "#results_folder=\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_annotated_normalized\"\n",
    "results_folder=\"../results/deep_learning_with_edge_feats_with_node_feats/results_synthetic_not_normalized\"\n",
    "\n",
    "output_df = load_results_data(results_folder)\n",
    "#Get the data name\n",
    "output_df[\"Data Train\"] = output_df[\"Data Train\"].apply(lambda x: os.path.basename(x))\n",
    "output_df[\"Data Test\"] = output_df[\"Data Test\"].apply(lambda x: os.path.basename(x))\n",
    "output_df = output_df.drop([\"Data Test\"], axis=1)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388c520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = output_df.groupby([\"Data Train\", \"Algorithm\", \"Angles\", \"Constraints\"]).agg({'ROC AUC Score': ['mean', 'std', 'min', 'max'],\n",
    "                                                                  'Accuracy': ['mean', 'std', 'min', 'max'],\n",
    "                                                                  'TPR': ['mean', 'std', 'min', 'max'],\n",
    "                                                                  'FPR': ['mean', 'std', 'min', 'max'],\n",
    "                                                                  'Precision': ['mean', 'std', 'min', 'max'],\n",
    "                                                                  'F1-Score': ['mean', 'std', 'min', 'max']})\n",
    "\n",
    "grouped = grouped.reset_index(level=['Data Train', 'Algorithm', \"Data Train\", 'Angles', 'Constraints'])\n",
    "\n",
    "def format_column(_mean, _min, _max, _std):\n",
    "    reference = _min if abs(_min) > abs(_max) else _max\n",
    "    difference = abs(_mean-reference)\n",
    "    return str(round(_mean, 3)) + \"±\" + str(round(difference, 3))\n",
    "\n",
    "numeric_cols = [\"ROC AUC Score\",\"Accuracy\",\"TPR\", \"FPR\",\t\"Precision\",\"F1-Score\"]\n",
    "for col in numeric_cols:  # Iterate over the first level of multi-level columns\n",
    "    cols = [(col, 'mean'), (col, 'min'), (col, 'max'), (col, 'std')]\n",
    "    grouped[(col,\"\")] = grouped.apply(lambda row: format_column(row[cols[0]], row[cols[1]], row[cols[2]], row[cols[3]]), axis=1)\n",
    "    grouped = grouped.drop(columns= cols)\n",
    "\n",
    "grouped.columns = grouped.columns.map(''.join)\n",
    "grouped = grouped[[\"Data Train\",\"Algorithm\", \"Constraints\",\"Angles\",\t\"ROC AUC Score\",\"Accuracy\",\"TPR\", \"FPR\",\"Precision\",\t\"F1-Score\"]]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cfaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Algorithm column\n",
    "grouped = grouped.sort_values(by=['Data Train', 'Angles', 'Algorithm'], ascending=[True, True, False]).reset_index(drop=True)\n",
    "\n",
    "grouped['Algorithm'] = grouped['Algorithm'].replace({\n",
    "    'GNN_Classifier_NonRecurrent': 'MPNN Non-Recurrent',\n",
    "    'GNN_Classifier_Recurrent': 'MPNN Recurrent'\n",
    "})\n",
    "\n",
    "# Add Angular Features information to Algorithm column\n",
    "grouped['Algorithm'] = grouped.apply(lambda row: f\"{row['Algorithm']} {'w/ Angular Features' if row['Angles'] else 'w/o Angular Features'}\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "#grouped = grouped.drop(columns=['Data Train', 'Angles'])\n",
    "grouped = grouped.drop(columns=['Angles'])\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0129514",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbbd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Input Dataset\n",
    "#input_folder = \"../data/vectors\"#real manually annotated\n",
    "#input_folder = \"../data/vectors_automatic_csv\"#real automatic segmentation\n",
    "input_folder = \"../data/synthetic_algo_200_points/\"#synthetic\n",
    "\n",
    "subplot_params = {\"projection\":\"3d\"}\n",
    "fig_all = plt.figure(figsize=(18, 9), dpi= 300)#12,9\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.15)#wspace-> horizontal hspace-> vertical\n",
    "rows = 2\n",
    "columns = 4\n",
    "plot_styles = {\n",
    "                \"nuclei\":{\"marker\":\"o\",\"color\":\"red\", \"alpha\":0.3},\n",
    "                \"golgi\":{\"marker\":\"o\",\"color\":\"green\", \"alpha\":0.3},\n",
    "                \"\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                #\"tp\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                #\"fp\": {\"color\": \"yellow\", \"dashed\": False, \"alpha\":1},\n",
    "                #\"tn\": None,\n",
    "                #\"fn\": {\"color\": \"blue\",  \"dashed\": True, \"alpha\":1}\n",
    "}\n",
    "\n",
    "for (i,file) in enumerate(os.listdir(input_folder)):\n",
    "    file_path_input = os.path.join(input_folder, file)\n",
    "    title = os.path.basename(file_path_input)\n",
    "    title = os.path.splitext(title)[0]\n",
    "    \n",
    "    #True Graph\n",
    "    figax = plt.subplot(rows, columns, i+1, **subplot_params)\n",
    "    df, nodes_df, edges_df = load_df_from_csv(file_path_input)\n",
    "    edge_labels = [\"\"]*len(edges_df)\n",
    "    df_figure = df_make_plot(figax, nodes_df, edges_df, edge_labels, title, add_legends=False)\n",
    "\n",
    "    \n",
    "add_legend_plot(fig_all, plot_styles)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted with labels\n",
    "def annote_figure(figax, annotations, fontsize = 7):\n",
    "    \n",
    "    start_point_y = 0.9\n",
    "    start_point_x = 1.1\n",
    "        \n",
    "    for i, annotation in enumerate(annotations):\n",
    "        figax.annotate(annotation, xy=(start_point_x, start_point_y - i * 0.1), \n",
    "                       xycoords=\"axes fraction\", fontsize=fontsize, color=\"black\")\n",
    "    return\n",
    "\n",
    "def get_edge_label(edges_df_true, edges_df_pred):\n",
    "    edges_dict_src_tgt = dict(zip(edges_df_true.source, edges_df_true.target))\n",
    "    edges_dict_tgt_src = dict(zip(edges_df_true.target, edges_df_true.source))\n",
    "    edges_dict_true = {**edges_dict_src_tgt, **edges_dict_tgt_src} #merge two dicts\n",
    "\n",
    "    #Get TP and FP\n",
    "    edge_labels = []\n",
    "    for idx, row in edges_df_pred.iterrows():\n",
    "        if(row[\"source\"] in edges_dict_true and edges_dict_true[row[\"source\"]]==row[\"target\"]):\n",
    "            edge_labels.append(\"tp\")\n",
    "        else:\n",
    "            edge_labels.append(\"fp\")\n",
    "    edges_df_pred[\"edge_label\"] = edge_labels\n",
    "\n",
    "    #Get FN\n",
    "    edges_dict_src_tgt = dict(zip(edges_df_pred.source, edges_df_pred.target))\n",
    "    edges_dict_tgt_src = dict(zip(edges_df_pred.target, edges_df_pred.source))\n",
    "    edges_dict_pred = {**edges_dict_src_tgt, **edges_dict_tgt_src}#merge two dicts\n",
    "    \n",
    "    rows = []\n",
    "    for idx, row in edges_df_true.iterrows():\n",
    "        if(row[\"source\"] not in edges_dict_pred or edges_dict_pred[row[\"source\"]]!=row[\"target\"]):\n",
    "            rows.append({\"source\":row[\"source\"], \"target\":row[\"target\"], \"edge_label\":\"fn\"})\n",
    "    fn_edges_df = pd.DataFrame(rows)\n",
    "\n",
    "    edges_df_pred = pd.concat([edges_df_pred, fn_edges_df], ignore_index=True, sort=False).reset_index(drop=True)\n",
    "    return edges_df_pred\n",
    "\n",
    "input_folder = \"../data/vectors\"\n",
    "\n",
    "#Manually annotated data - Classical Bipartite Matching algorithms\n",
    "#results_folder = \"../results/HopcroftKarp_RealDataManuallyAnnotated_k7\"\n",
    "#results_folder = \"../results/JonkerVolgenant_RealDataManuallyAnnotated_k7\"\n",
    "\n",
    "#Manually annotated data - MPNN Recurrent With Angular Features\n",
    "results_folder = \"../results/deep_learning_with_edge_feats_with_node_feats/results_real_annotated_normalized/trial1/Results_0\"#without constraints\n",
    "#results_folder = \"../results/deep_learning_with_edge_feats_with_node_feats/results_real_annotated_normalized/trial1/Results_0_constraints\"#MPNN Recurrent Greedy W/o Threshold\n",
    "#results_folder = \"../results/deep_learning_with_edge_feats_with_node_feats/results_real_annotated_normalized/trial1/Results_0_constraints_threshold\"#MPNN Recurrent Greedy W/ Threshold\n",
    "\n",
    "subplot_params = {\"projection\":\"3d\"}\n",
    "fig_all = plt.figure(figsize=(18, 9), dpi= 300)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.15)#wspace-> horizontal hspace-> vertical\n",
    "rows = 2\n",
    "columns = 4\n",
    "plot_styles = {\n",
    "                \"nuclei\":{\"marker\":\"o\",\"color\":\"red\", \"alpha\":0.3},\n",
    "                \"golgi\":{\"marker\":\"o\",\"color\":\"green\", \"alpha\":0.3},\n",
    "                #\"\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                \"tp\": {\"color\": \"black\",  \"dashed\": False, \"alpha\":1},\n",
    "                \"fp\": {\"color\": \"blue\", \"dashed\": True, \"alpha\":1},\n",
    "                \"tn\": None,\n",
    "                \"fn\": {\"color\": \"yellow\",  \"dashed\": True, \"alpha\":1}\n",
    "}\n",
    "\n",
    "tp_total=0\n",
    "fp_total=0\n",
    "fn_total=0\n",
    "\n",
    "for (index_fig,file) in enumerate(os.listdir(input_folder)):\n",
    "    file_path_input = os.path.join(input_folder, file)\n",
    "    file_path_results = os.path.join(results_folder, file)\n",
    "    title = os.path.basename(file_path_input)\n",
    "    title = os.path.splitext(title)[0]\n",
    "\n",
    "    df_true, nodes_df_true, edges_df_true = load_df_from_csv(file_path_input)\n",
    "    df_pred, nodes_df_pred, edges_df_pred = load_df_from_csv(file_path_results)\n",
    "    nodes_df_pred[[\"X\", \"Y\", \"Z\"]] += 1#correct the transformation that is applied when reading file in load_df_from_csv\n",
    "\n",
    "    #map to same reference of IDs for nodes\n",
    "    nodes_df = pd.concat([nodes_df_true, nodes_df_pred], ignore_index=True, sort=False).reset_index(drop=True)\n",
    "    nodes_df[\"ID\"] = nodes_df.index\n",
    "    nodes_dict = dict(zip(zip(nodes_df['X'], nodes_df['Y'], nodes_df['Z']), nodes_df['ID']))\n",
    "\n",
    "    nodes_df_true[\"NEW_ID\"] = nodes_df_true.apply(lambda x: nodes_dict[tuple([x[\"X\"], x[\"Y\"], x[\"Z\"]])], axis=1)#get new global ID\n",
    "    nodes_df_true_dict = dict(zip(nodes_df_true.ID, nodes_df_true.NEW_ID))\n",
    "    edges_df_true[\"source\"] = edges_df_true[\"source\"].apply(lambda x : nodes_df_true_dict[x])\n",
    "    edges_df_true[\"target\"] = edges_df_true[\"target\"].apply(lambda x : nodes_df_true_dict[x])\n",
    "    \n",
    "    nodes_df_pred[\"NEW_ID\"] = nodes_df_pred.apply(lambda x: nodes_dict[tuple([x[\"X\"], x[\"Y\"], x[\"Z\"]])], axis=1)#get new global ID\n",
    "    nodes_df_pred_dict = dict(zip(nodes_df_pred.ID, nodes_df_pred.NEW_ID))\n",
    "    edges_df_pred[\"source\"] = edges_df_pred[\"source\"].apply(lambda x : nodes_df_pred_dict[x])\n",
    "    edges_df_pred[\"target\"] = edges_df_pred[\"target\"].apply(lambda x : nodes_df_pred_dict[x])\n",
    "\n",
    "    edges_df_pred= get_edge_label(edges_df_true, edges_df_pred)\n",
    "\n",
    "    #Plot Graph\n",
    "    figax = plt.subplot(rows, columns, index_fig+1, **subplot_params)\n",
    "    edge_labels = edges_df_pred[\"edge_label\"].tolist()\n",
    "    df_figure = df_make_plot(figax, nodes_df, edges_df_pred, edge_labels, title, add_legends=False, plot_styles=plot_styles)\n",
    "    sample_metrics = dict(edges_df_pred[\"edge_label\"].value_counts())\n",
    "    tp_total+=sample_metrics['tp'] if 'tp' in sample_metrics else 0\n",
    "    fp_total+=sample_metrics['fp'] if 'fp' in sample_metrics else 0\n",
    "    fn_total+=sample_metrics['fn'] if 'fn' in sample_metrics else 0\n",
    "    sample_metrics = [\n",
    "        f\"TP: {sample_metrics['tp'] if 'tp' in sample_metrics else 0}\",\n",
    "        f\"FP: {sample_metrics['fp'] if 'fp' in sample_metrics else 0}\",\n",
    "        f\"FN: {sample_metrics['fn'] if 'fn' in sample_metrics else 0}\"\n",
    "    ]\n",
    "\n",
    "    annote_figure(figax, sample_metrics)\n",
    "\n",
    "fig_all_legend = add_legend_plot(fig_all, plot_styles)\n",
    "\n",
    "\n",
    "params_file_path = os.path.join(results_folder, \"params.json\")\n",
    "if os.path.isfile(params_file_path):\n",
    "    with open(params_file_path, \"r\") as f:\n",
    "        params_file = json.load(f)\n",
    "    rouc_auc_score = params_file[\"aggregated_metrics\"][\"rouc_auc_score\"]\n",
    "\n",
    "    if \"constraints\" in results_folder:\n",
    "        if \"threshold\" in results_folder:\n",
    "            params_dict = params_file[\"aggregated_metrics\"][\"@best\"][\"@constraints\"][\"metrics\"]\n",
    "        else:\n",
    "            params_dict = params_file[\"aggregated_metrics\"][\"@constraints\"][\"metrics\"]\n",
    "    else:\n",
    "        params_dict = params_file[\"aggregated_metrics\"][\"@best\"][\"metrics\"]\n",
    "\n",
    "    count_annotations = [\n",
    "            \"Overall Metrics:\",\n",
    "            f\"Acc.: {round(params_dict['acc'],3)}\",\n",
    "            f\"TPR: {round(params_dict['TPR'],3)}\",\n",
    "            f\"FPR: {round(params_dict['FPR'],3)}\",\n",
    "            f\"Prec.: {round(params_dict['precision'],3)}\",\n",
    "            f\"TP: {params_dict['tp']}\",\n",
    "            f\"FP: {params_dict['fp']}\",\n",
    "            f\"TN: {params_dict['tn']}\",\n",
    "            f\"FN: {params_dict['fn']}\"\n",
    "    ]\n",
    "    count_annotations = \"\\n\".join(count_annotations)\n",
    "else:\n",
    "    count_annotations = \"\\n\".join([\n",
    "            \"Overall Metrics:\",\n",
    "            #f\"Acc.: {params_dict['acc']}\",\n",
    "            #f\"Prec.: {round((tp_total/(tp_total+fp_total)),3)}\",\n",
    "            #f\"Recall: {round((tp_total/(tp_total+fp_total)),3)}\",\n",
    "            f\"TP: {tp_total}\",\n",
    "            f\"FP: {fp_total}\",\n",
    "            #f\"TN: {tn_total}\",\n",
    "            f\"FN: {fn_total}\"\n",
    "    ])\n",
    "\n",
    "# Add the annotation to the figure\n",
    "fig_all.text(0.98, 0.9, count_annotations, ha='right', va='top', fontsize=\"small\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c928b8a5",
   "metadata": {},
   "source": [
    "### True vs Pred graph by graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot input dataset vs predicted\n",
    "input_folder = \"../data/vectors\"\n",
    "\n",
    "results_folder_list = [\n",
    "    {\"title\":\"(b) Jonker-Volgenant\", \"path\": r\"../results/JonkerVolgenant_RealDataCNNAutomatic_k10/\"},\n",
    "    {\"title\":\"(c) MPNN Non-Recurrent w/o Constraints\", \"path\":r\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_automatic_normalized/trial1/Results_3\"},\n",
    "    {\"title\":\"(d) MPNN Non-Recurrent w/ Constraints \\\"Greedy w/ Threshold\\\"\", \"path\": r\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_automatic_normalized/trial1/Results_3_constraints_threshold\"},\n",
    "]\n",
    "\n",
    "\n",
    "figures = []\n",
    "number_of_cols = len(results_folder_list)+1\n",
    "for file in os.listdir(input_folder):\n",
    "    file_path_input = os.path.join(input_folder, file)\n",
    "    graph_name = os.path.splitext(os.path.basename(file_path_input))[0]\n",
    "    # Check if the graph_name ends with \"_BC\"\n",
    "    if graph_name.endswith(\"_BC\"):\n",
    "        # Remove the \"_BC\" suffix\n",
    "        graph_name = graph_name[:-3]\n",
    "        \n",
    "    title = \"Predictions for \"+ graph_name+\" without Angular Features\"\n",
    "\n",
    "    subplot_params = {\"projection\":\"3d\"}\n",
    "    fig_all = plt.figure(figsize=(26, 9), dpi= 300, layout='constrained')#18,9\n",
    "    #plt.subplots_adjust(wspace=0.4, hspace=0.15)#wspace-> horizontal hspace-> vertical\n",
    "\n",
    "    #True Graph\n",
    "    figax = plt.subplot(1, number_of_cols, 1, **subplot_params)\n",
    "    df, nodes_df, edges_df = load_df_from_csv(file_path_input)\n",
    "    edge_labels = [\"\"]*len(edges_df)\n",
    "    df_figure = df_make_plot(figax, nodes_df, edges_df, edge_labels, \"(a) Ground-truth\")\n",
    "\n",
    "    for i in range(2, number_of_cols+1):#start at 2, end at number_of_cols\n",
    "        results_folder = results_folder_list[i-2]\n",
    "        file_path_results = os.path.join(results_folder[\"path\"], file)\n",
    "        figax = plt.subplot(1, number_of_cols, i, **subplot_params)\n",
    "        df, nodes_df, edges_df = load_df_from_csv(file_path_results)\n",
    "        edge_labels = [\"\"]*len(edges_df)\n",
    "        df_figure = df_make_plot(figax, nodes_df, edges_df, edge_labels, results_folder[\"title\"])\n",
    "\n",
    "    #Append figure to figures List\n",
    "    fig_all.suptitle(title, y=0.95, fontsize=20)#y=0.85\n",
    "    plt.show()\n",
    "    figures.append(fig_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fa826",
   "metadata": {},
   "source": [
    "### Merge images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e02e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def merge_images_vertically(image_paths, output_path):\n",
    "    images = [Image.open(image_path) for image_path in image_paths]\n",
    "    \n",
    "    # Find the maximum width\n",
    "    max_width = max(image.size[0] for image in images)\n",
    "    \n",
    "    # Resize all images to the maximum width\n",
    "    resized_images = [image.resize((max_width, int(image.size[1] * (max_width / image.size[0]))), Image.LANCZOS) for image in images]\n",
    "    \n",
    "    total_height = sum(image.size[1] for image in resized_images)\n",
    "\n",
    "    new_image = Image.new('RGB', (max_width, total_height))\n",
    "\n",
    "    y_offset = 0\n",
    "    for image in resized_images:\n",
    "        new_image.paste(image, (0, y_offset))\n",
    "        y_offset += image.size[1]\n",
    "\n",
    "    new_image.save(output_path)\n",
    "\n",
    "# Example usage:\n",
    "image_paths = [\n",
    "    #r\"../figures/real_automatic_normalized/crop1.png\",\n",
    "      #r\"../figures/real_automatic_normalized/crop2.png\",\n",
    "      #r\"../figures/real_automatic_normalized/crop3.png\",\n",
    "      r\"../figures/real_automatic_normalized/crop4.png\",\n",
    "      r\"../figures/real_automatic_normalized/crop5.png\",\n",
    "      r\"../figures/real_automatic_normalized/crop6.png\",\n",
    "      r\"../figures/real_automatic_normalized/crop7.png\",\n",
    "      #r\"../figures/real_automatic_normalized/crop8.png\",\n",
    "]  # Replace with your image paths\n",
    "output_path = \"merged-crops-4-5-7.jpg\"  # Specify the output path\n",
    "\n",
    "merge_images_vertically(image_paths, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0301e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
