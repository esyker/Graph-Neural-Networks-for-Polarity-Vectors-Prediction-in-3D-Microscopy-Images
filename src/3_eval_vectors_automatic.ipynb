{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the necessary packages\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import warnings\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tifffile\n",
    "from math import*\n",
    "import json\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'GNN'\n",
    "#Choose directory containing the predicted nucleus and golgi centroids \n",
    "\n",
    "gt_dir = r\"../data/vectors\" #directory with the ground truth vectors\n",
    "img_dir = r\"../data/images\"#directory with images\n",
    "\n",
    "#nuclei_thresholds = [8.8]\n",
    "#golgi_thresholds = [4.4]\n",
    "nuclei_thresholds = [10]\n",
    "golgi_thresholds = [6]\n",
    "levels_ = [0]\n",
    "lvl_ = 0\n",
    "\n",
    "numbers_ = [0, 1, 2, 3, 4, 5, 6, 7] #crops\n",
    "\n",
    "## name of the images\n",
    "imgs = ['Crop1', 'Crop2', 'Crop3', 'Crop4', 'Crop5_BC', 'Crop6_BC', 'Crop7_BC','Crop8_BC']\n",
    "\n",
    "image_dimensions = [[0.333,0.333,0.270], [0.333,0.333,0.270], [0.333,0.333,0.270], [0.333,0.333,0.270],\n",
    "              [0.333,0.333,0.270], [0.333,0.333,0.270], [0.333,0.333,0.400], [0.333,0.333,0.400]] #um\n",
    "\n",
    "info = ['test']*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define the metrics ''' \n",
    "def square_rooted(x):\n",
    "    return round(np.sqrt(sum([a*a for a in x])),3)\n",
    " \n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "\n",
    "#Euclidean distance computed in um\n",
    "def distance_um(p, q, dimx, dimy, dimz):\n",
    "    dist_um = (((p[0]-q[0])*dimx)**2)+(((p[1]-q[1])*dimy)**2)+(((p[2]-q[2])*dimz)**2)\n",
    "    return np.sqrt(dist_um) \n",
    "\n",
    "#ignore the borders of the image\n",
    "def inside_img(coord,img_dim_x,img_dim_y,img_dim_z,x_y_lim,z_lim):\n",
    "    return coord[0]<img_dim_x-x_y_lim and coord[0]>x_y_lim and coord[1]<img_dim_y-x_y_lim and coord[1]>x_y_lim and coord[2]<img_dim_z-z_lim and coord[2]>0\n",
    "\n",
    "#modify Constraints Col\n",
    "def transform_constraints_column(col):\n",
    "    \"\"\"\n",
    "    This function takes a string value from the 'Constraints' column and returns:\n",
    "        - False if the value doesn't contain 'constraints_'\n",
    "        - The substring after 'constraints_' (inclusively) otherwise\n",
    "    \"\"\"\n",
    "    if 'constraints' not in col:\n",
    "        return False\n",
    "    else:\n",
    "        return \"constraints\"+col.split('constraints')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results_batch(pred_subfolder, image_nb, allmetrics, metrics_stats):\n",
    "    pred_vectors = os.path.join(pred_subfolder, imgs[image_nb] + '.csv')\n",
    "    gt_vectors = os.path.join(gt_dir, imgs[image_nb] + '.csv')\n",
    "\n",
    "    ## read the image and get its dimensions\n",
    "    image = tifffile.imread(os.path.join(img_dir, imgs[image_nb] + '.tif'))\n",
    "    (img_dim_x, img_dim_y, img_dim_z, channels) = np.shape(image)\n",
    "\n",
    "    #voxel's physical dimensions\n",
    "    x_spacing = image_dimensions[image_nb][0]\n",
    "    y_spacing = image_dimensions[image_nb][1]\n",
    "    z_spacing = image_dimensions[image_nb][2]\n",
    "    \n",
    "    #limits to ignore vectors at the borders of the image\n",
    "    x_y_lim = int(7/x_spacing)  #(voxels)  16\n",
    "    z_lim = int(5/z_spacing)    #(voxels)  5\n",
    "\n",
    "    #print('Reading the csv file with the ground truth vectors')\n",
    "    ## nuclei and golgi centroids\n",
    "    nuclei_centroids_gt = [] \n",
    "    golgi_centroids_gt = []\n",
    "    \n",
    "    #open the csv file and save the gt nucleus and Golgi centroids\n",
    "    file = open(gt_vectors, \"rU\")\n",
    "    reader = csv.reader(file, delimiter=';')\n",
    "    for row in reader:\n",
    "        if row[0] != 'YN,XN,ZN,YG,XG,ZG':\n",
    "            aux = row[0].split(\",\")\n",
    "            YN = int(float(aux[0]))-1\n",
    "            XN = int(float(aux[1]))-1\n",
    "            ZN = int(float(aux[4]))-1\n",
    "            YG = int(float(aux[2]))-1\n",
    "            XG = int(float(aux[3]))-1\n",
    "            ZG = int(float(aux[5]))-1\n",
    "            \n",
    "            if inside_img(np.asarray([XN,YN,ZN]), img_dim_x, img_dim_y, img_dim_z, x_y_lim, z_lim) and inside_img(np.asarray([XG,YG,ZG]), img_dim_x,img_dim_y,img_dim_z,x_y_lim,z_lim):\n",
    "                nuclei_centroids_gt.append((XN,YN,ZN))\n",
    "                golgi_centroids_gt.append((XG,YG,ZG))     \n",
    "    \n",
    "    golgi_centroids_gt = np.asarray(golgi_centroids_gt)\n",
    "    nuclei_centroids_gt = np.asarray(nuclei_centroids_gt)\n",
    "    \n",
    "    #Remove predicted nuclei and golgi at image borders\n",
    "    n_centroids = []\n",
    "    g_centroids = []\n",
    "    #open the csv file and save the gt nucleus and Golgi centroids\n",
    "    file = open(pred_vectors, \"rU\")\n",
    "    reader = csv.reader(file, delimiter=';')\n",
    "    for row in reader:\n",
    "        if row[0] != 'YN,XN,ZN,YG,XG,ZG':\n",
    "            aux = row[0].split(\",\")\n",
    "            YN = int(float(aux[0]))-1\n",
    "            XN = int(float(aux[1]))-1\n",
    "            ZN = int(float(aux[4]))-1\n",
    "            YG = int(float(aux[2]))-1\n",
    "            XG = int(float(aux[3]))-1\n",
    "            ZG = int(float(aux[5]))-1\n",
    "            \n",
    "            if inside_img(np.asarray([XN,YN,ZN]), img_dim_x, img_dim_y, img_dim_z, x_y_lim, z_lim) and inside_img(np.asarray([XG,YG,ZG]), img_dim_x,img_dim_y,img_dim_z,x_y_lim,z_lim):\n",
    "                if distance_um([XN,YN,ZN], [XG,YG,ZG], x_spacing, y_spacing, z_spacing)<18:\n",
    "                    n_centroids.append((XN,YN,ZN))\n",
    "                    g_centroids.append((XG,YG,ZG))     \n",
    "            \n",
    "    nuclei_centroids = np.asarray(n_centroids)\n",
    "    golgi_centroids = np.asarray(g_centroids)\n",
    "    \n",
    "    #print('Evaluation')\n",
    "    ''' Assignment nuclei centroids '''\n",
    "    ## compute the Euclidean distance between the predicted and ground truth centroids\n",
    "    matrix = np.zeros((len(nuclei_centroids),len(nuclei_centroids_gt)))\n",
    "    \n",
    "    ## build the cost matrix\n",
    "    for i in range(0,len(nuclei_centroids)):\n",
    "        for j in range(0,len(nuclei_centroids_gt)):\n",
    "            matrix[i,j] = distance_um(nuclei_centroids[i], nuclei_centroids_gt[j], x_spacing, y_spacing, z_spacing) + distance_um(golgi_centroids[i], golgi_centroids_gt[j], x_spacing, y_spacing, z_spacing)\n",
    "    \n",
    "    matrix[matrix>10] = 2000\n",
    "    \n",
    "    ## method to solve the linear assignment problem\n",
    "    row_ind, col_ind = linear_sum_assignment(matrix)\n",
    "    \n",
    "    ''' Compute the metrics for the vectors '''\n",
    "    for n_th, g_th, thlvl in zip(nuclei_thresholds, golgi_thresholds, levels_):\n",
    "        metrics = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                      \"cosine similarity\", \"vec_error\", \"nuclei\", \"golgi\"])\n",
    "\n",
    "        if thlvl==lvl_:\n",
    "            index_tp = []  ## positions in vectors nuclei_centroids, golgi_centroids, that are\n",
    "                            ## true positives\n",
    "                            \n",
    "            index_tp_gt = [] ## positions in vectors nuclei_centroids_gt and golgi_centroids_gt,\n",
    "                              ## that correspond to true positives\n",
    "\n",
    "        for i in range(0, len(row_ind)):\n",
    "            n_coord = nuclei_centroids[row_ind[i]]\n",
    "            g_coord = golgi_centroids[row_ind[i]]\n",
    "        \n",
    "            vec = g_coord - n_coord\n",
    "        \n",
    "            n_coord_gt = nuclei_centroids_gt[col_ind[i]]\n",
    "            g_coord_gt = golgi_centroids_gt[col_ind[i]]\n",
    "        \n",
    "            vec_gt = g_coord_gt - n_coord_gt\n",
    "            \n",
    "            dist_n_centroids = distance_um(n_coord, n_coord_gt, x_spacing, y_spacing, z_spacing)\n",
    "            dist_g_centroids = distance_um(g_coord, g_coord_gt, x_spacing, y_spacing, z_spacing)\n",
    "            vec_error = distance_um(vec, vec_gt, x_spacing, y_spacing, z_spacing)\n",
    "            \n",
    "            cos_sim = cosine_similarity(vec, vec_gt)\n",
    "            \n",
    "            if dist_n_centroids<=n_th and dist_g_centroids<=g_th:\n",
    "                res = {\"Image\": imgs[image_nb], \"Method\": method, \"Type\": info[image_nb], \"NucleusTh\": n_th, \"GolgiTh\": g_th,\n",
    "                       \"Threshold_level\": thlvl,\n",
    "                       \"cosine similarity\": abs(cos_sim), \"vec_error\": vec_error, \n",
    "                       \"nuclei\": dist_n_centroids, \"golgi\": dist_g_centroids}\n",
    "                \n",
    "                res_aux = {\"Image\": imgs[image_nb], \"Method\": method, \"Type\": info[image_nb], \"NucleusTh\": n_th, \"GolgiTh\": g_th,\n",
    "                       \"Threshold_level\": thlvl, \"index_tp_gt\": col_ind[i],\n",
    "                       \"cosine similarity\": abs(cos_sim), \"vec_error\": vec_error, \n",
    "                       \"nuclei\": dist_n_centroids, \"golgi\": dist_g_centroids}\n",
    "                \n",
    "                row_aux = len(allmetrics)\n",
    "                allmetrics.loc[row_aux] = res_aux\n",
    "                \n",
    "                row = len(metrics)\n",
    "                metrics.loc[row] = res\n",
    "                \n",
    "                row_stats = len(metrics_stats)\n",
    "                metrics_stats.loc[row_stats] = res\n",
    "                \n",
    "                if thlvl==lvl_:\n",
    "                    index_tp.append(row_ind[i])\n",
    "                    index_tp_gt.append(col_ind[i])\n",
    "                \n",
    "        \n",
    "        metrics_mean = metrics.select_dtypes(include=[np.number]).mean()\n",
    "        metrics_std = metrics.select_dtypes(include=[np.number]).std()\n",
    "        \n",
    "        TP = len(metrics)\n",
    "        \n",
    "        FP = np.shape(golgi_centroids)[0] - len(metrics)\n",
    "        \n",
    "        FN = np.shape(golgi_centroids_gt)[0] - len(metrics)\n",
    "\n",
    "        TN = len(pred_vectors)-TP-FP-FN\n",
    "        \n",
    "        ACC = (TP+TN)/(TP+FP+TN+FN)\n",
    "        TPR = TP/(TP+FN)\n",
    "        \n",
    "        FPR = FP/(FP+TP)\n",
    "        \n",
    "        FNR = FN/(FN+TP)\n",
    "        \n",
    "        PRECISION = TP/(TP+FP)\n",
    "        RECALL = TPR\n",
    "        F1_SCORE = 2*PRECISION*RECALL/(PRECISION+RECALL)\n",
    "        \n",
    "        res = {\"Image\": imgs[image_nb], \"Method\": method, \"Type\": info[image_nb], \n",
    "               \"NucleusTh\": n_th, \"GolgiTh\": g_th, \"Threshold_level\": thlvl,\n",
    "               \"CosineSimilarityM\": metrics_mean['cosine similarity'],\n",
    "               \"CosineSimilaritySTD\": metrics_std['cosine similarity'], \n",
    "               \"VecErrorM\": metrics_mean['vec_error'],\n",
    "               \"VecErrorSTD\": metrics_std['vec_error'],\n",
    "               \"DistanceNuM\": metrics_mean['nuclei'], \n",
    "               \"DistanceNuSTD\": metrics_std['nuclei'], \n",
    "               \"DistanceGoM\": metrics_mean['golgi'], \n",
    "               \"DistanceGoSTD\": metrics_std['golgi'], \n",
    "               \"TP\": TP, \n",
    "               \"FP\": FP, \n",
    "               \"FN\": FN, \n",
    "               \"TPR\": TPR, \n",
    "               \"FPR\": FPR,\n",
    "               \"FNR\": FNR,\n",
    "               \"ACC\":ACC,\n",
    "               \"PRECISION\":PRECISION,\n",
    "               \"F1_SCORE\":F1_SCORE}\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment here to use LATEST results with data WITHOUT normalization\n",
    "#pred_dir = r\"../results/deep_learning/results_real_automatic_not_normalized/trial1/Results_0_constraints/\" #GNN w/ Angular Features\n",
    "#pred_dir = r\"../results/deep_learning/results_real_automatic_not_normalized/trial1/Results_1_constraints/\" #GNN w/o Angular Features\n",
    "#pred_dir = r\"../results/deep_learning/results_real_automatic_not_normalized/trial1/Results_2_constraints/\" #MLP w/ Angular Features\n",
    "#pred_dir = r\"../results/deep_learning/results_real_automatic_not_normalized/trial1/Results_3_constraints/\" #MLP w/o Angular Features\n",
    "\n",
    "#Uncomment here to use results for classical algorithms\n",
    "#pred_dir = r\"../results/HopcroftKarp_RealDataCNNAutomatic_k10/\" #Hopcroft-Karp\n",
    "pred_dir = r\"../results/JonkerVolgenant_RealDataCNNAutomatic_k10/\" #Jonker-Volgenant\n",
    "\n",
    "\n",
    "performance_metrics = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                              \"CosineSimilarityM\",\n",
    "                                              \"CosineSimilaritySTD\", \"VecErrorM\",\"VecErrorSTD\",\n",
    "                                              \"DistanceNuM\", \"DistanceNuSTD\", \"DistanceGoM\",\n",
    "                                              \"DistanceGoSTD\", \"TP\", \"FP\", \"FN\",\"ACC\", \"TPR\", \"FPR\", \"FNR\", \"PRECISION\", \"F1_SCORE\"])\n",
    "\n",
    "metrics_stats = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                        \"cosine similarity\", \"vec_error\", \"nuclei\", \"golgi\"])\n",
    "\n",
    "allmetrics = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                      \"index_tp_gt\", \"cosine similarity\", \"vec_error\", \"nuclei\", \"golgi\"])\n",
    "\n",
    "for image_nb in tqdm(numbers_):\n",
    "        res = eval_results_batch(pred_dir, image_nb, allmetrics, metrics_stats)\n",
    "        \n",
    "        \n",
    "        row = len(performance_metrics)\n",
    "        performance_metrics.loc[row] = res\n",
    "\n",
    "final_metrics = performance_metrics.groupby([\"Threshold_level\"], as_index=False).agg({'CosineSimilarityM': np.mean,\n",
    "                                                 \"CosineSimilaritySTD\": np.mean,\n",
    "                                                 \"VecErrorM\": np.mean,\n",
    "                                                 \"VecErrorSTD\": np.mean,\n",
    "                                                 \"DistanceNuM\": np.mean, \n",
    "                                                 \"DistanceNuSTD\": np.mean, \n",
    "                                                 \"DistanceGoM\": np.mean, \n",
    "                                                 \"DistanceGoSTD\": np.mean, \n",
    "                                                 \"TP\": np.sum, \n",
    "                                                 \"FP\": np.sum, \n",
    "                                                 \"FN\": np.sum, \n",
    "                                                 \"ACC\": np.mean,\n",
    "                                                 \"TPR\": np.mean, \n",
    "                                                 \"FPR\": np.mean,\n",
    "                                                 \"FNR\": np.mean,\n",
    "                                                 \"PRECISION\": np.mean,\n",
    "                                                 \"F1_SCORE\":np.mean})\n",
    "final_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_metrics.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_dfs = []\n",
    "\n",
    "list_pred_dirs = [r\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_automatic_normalized/trial1/\",\n",
    "                    r\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_automatic_normalized/trial2/\",\n",
    "                  r\"../results/deep_learning_with_edge_feats_with_node_feats/results_real_automatic_normalized/trial3/\",\n",
    "                  ]\n",
    "\n",
    "for pred_dir in tqdm(list_pred_dirs):\n",
    "    records = []\n",
    "    for pred_subfolder in os.listdir(pred_dir):\n",
    "        \n",
    "        pred_subfolder = os.path.join(pred_dir, pred_subfolder)\n",
    "\n",
    "        performance_metrics = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                              \"CosineSimilarityM\",\n",
    "                                              \"CosineSimilaritySTD\", \"VecErrorM\",\"VecErrorSTD\",\n",
    "                                              \"DistanceNuM\", \"DistanceNuSTD\", \"DistanceGoM\",\n",
    "                                              \"DistanceGoSTD\", \"TP\", \"FP\", \"FN\", \"ACC\", \"TPR\", \"FPR\", \"FNR\", \"PRECISION\", \"F1_SCORE\"])\n",
    "\n",
    "        metrics_stats = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                                \"cosine similarity\", \"vec_error\", \"nuclei\", \"golgi\"])\n",
    "\n",
    "        allmetrics = pd.DataFrame(columns = [\"Image\", \"Method\", \"Type\", \"NucleusTh\", \"GolgiTh\", \"Threshold_level\",\n",
    "                                            \"index_tp_gt\", \"cosine similarity\", \"vec_error\", \"nuclei\", \"golgi\"])\n",
    "        for image_nb in numbers_:\n",
    "\n",
    "            res = eval_results_batch(pred_subfolder, image_nb, allmetrics, metrics_stats)\n",
    "            row = len(performance_metrics)\n",
    "            performance_metrics.loc[row] = res\n",
    "            \n",
    "\n",
    "        #Aggregate Metrics\n",
    "        final_metrics = performance_metrics.groupby([\"Threshold_level\"], as_index=False).agg({'CosineSimilarityM': np.mean,\n",
    "                                                 \"CosineSimilaritySTD\": np.mean,\n",
    "                                                 \"VecErrorM\": np.mean,\n",
    "                                                 \"VecErrorSTD\": np.mean,\n",
    "                                                 \"DistanceNuM\": np.mean, \n",
    "                                                 \"DistanceNuSTD\": np.mean, \n",
    "                                                 \"DistanceGoM\": np.mean, \n",
    "                                                 \"DistanceGoSTD\": np.mean, \n",
    "                                                 \"TP\": np.sum, \n",
    "                                                 \"FP\": np.sum, \n",
    "                                                 \"FN\": np.sum, \n",
    "                                                 \"ACC\": np.mean,\n",
    "                                                 \"TPR\": np.mean, \n",
    "                                                 \"FPR\": np.mean,\n",
    "                                                 \"FNR\": np.mean,\n",
    "                                                 \"PRECISION\": np.mean,\n",
    "                                                 \"F1_SCORE\":np.mean})\n",
    "\n",
    "        #print(final_metrics)\n",
    "        record = {}\n",
    "        params_path = os.path.join(pred_subfolder, \"params.json\")\n",
    "        with open(params_path, 'r') as file:\n",
    "            params_data = json.load(file)\n",
    "        record.update(params_data[\"job_parameters\"])\n",
    "        record.update(final_metrics.to_dict('records')[0])\n",
    "        record[\"Constraints\"] = os.path.basename(pred_subfolder)\n",
    "        records.append(record)\n",
    "\n",
    "    #Get the dataframe of the records\n",
    "    records_df = pd.DataFrame(records)\n",
    "    records_df = records_df[[\"edge_feats\", \"model_type\",  \"Constraints\",\n",
    "                            'Threshold_level',\n",
    "                            'CosineSimilarityM', 'CosineSimilaritySTD', 'VecErrorM', 'VecErrorSTD',\n",
    "                            'DistanceNuM', 'DistanceNuSTD', 'DistanceGoM', 'DistanceGoSTD', 'TP',\n",
    "                            'FP', 'FN', 'ACC', 'TPR', 'FPR', 'FNR', 'PRECISION', 'F1_SCORE']]\n",
    "\n",
    "    #modify angular features col\n",
    "    records_df = records_df.rename(columns={'edge_feats': 'Edge Feats'})\n",
    "    records_df[\"Edge Feats\"] = records_df[\"Edge Feats\"].apply(lambda x: (\"New \" if \"x1\" in x else \"\") + \n",
    "                                                           (\"Angular\" if any(\"angle\" in item for item in x) else \"Cartesian\"))\n",
    "\n",
    "    #modify model_type col\n",
    "    model_type_transform = {\"GNN_Classifier\":\"GNN\"}\n",
    "    records_df[\"model_type\"] = records_df[\"model_type\"].apply(lambda x: model_type_transform.get(x, x)) \n",
    "\n",
    "    # Apply the transformation using vectorized function\n",
    "    records_df['Constraints'] = records_df['Constraints'].apply(transform_constraints_column)\n",
    "    constraints_transform = {\"constraints\":\"Greedy\", \"constraints_threshold\":\"Greedy w/ Threshold\", \"constraints_opt\": \"Optimization\"}\n",
    "    records_df['Constraints'] = records_df['Constraints'].apply(lambda x : constraints_transform.get(x,x))\n",
    "    trials_dfs.append(records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _trial_df in trials_dfs:\n",
    "    display(_trial_df[[\"Edge Feats\",\"model_type\",\"Constraints\",\"CosineSimilarityM\",\"CosineSimilaritySTD\",\"VecErrorM\",\"VecErrorSTD\",\"ACC\",\"TPR\",\"FPR\",\"PRECISION\",\"F1_SCORE\"]].sort_values(by=['Edge Feats', 'Constraints','model_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(trials_dfs)\n",
    "grouped = combined_df.groupby(['Edge Feats', 'model_type', 'Constraints']).agg(\n",
    "    {'Threshold_level': ['mean', 'std', 'min', 'max'],\n",
    "    'CosineSimilarityM': ['mean', 'std', 'min', 'max'],\n",
    "    'CosineSimilaritySTD': ['mean', 'std', 'min', 'max'],\n",
    "    'VecErrorM': ['mean', 'std', 'min', 'max'],\n",
    "    'VecErrorSTD': ['mean', 'std', 'min', 'max'],\n",
    "\n",
    "    'DistanceNuM': ['mean', 'std', 'min', 'max'],\n",
    "    'DistanceNuSTD': ['mean', 'std', 'min', 'max'],\n",
    "    'DistanceGoM': ['mean', 'std', 'min', 'max'],\n",
    "    'DistanceGoSTD': ['mean', 'std', 'min', 'max'],\n",
    "\n",
    "    'TP': ['mean', 'std', 'min', 'max'],\n",
    "    'FP': ['mean', 'std', 'min', 'max'],\n",
    "    'FN': ['mean', 'std', 'min', 'max'],\n",
    "    'ACC': ['mean', 'std', 'min', 'max'],\n",
    "    'TPR': ['mean', 'std', 'min', 'max'],\n",
    "    'FPR': ['mean', 'std', 'min', 'max'],\n",
    "    'FNR': ['mean', 'std', 'min', 'max'],\n",
    "    'PRECISION': ['mean', 'std', 'min', 'max'],\n",
    "    'F1_SCORE': ['mean', 'std', 'min', 'max']\n",
    "    })\n",
    "\n",
    "grouped = grouped.reset_index(level=['Edge Feats', 'model_type', 'Constraints'])\n",
    "\n",
    "def format_column(_mean, _min, _max, _std):\n",
    "    reference = abs(_min) if abs(_min) > abs(_max) else abs(_max)\n",
    "    difference = abs(_mean-reference)\n",
    "    return str(round(_mean, 3)) + \"Â±\" + str(round(difference, 3))\n",
    "\n",
    "numeric_cols = ['Threshold_level', 'CosineSimilarityM', 'CosineSimilaritySTD',\n",
    "     'VecErrorM', 'VecErrorSTD', 'DistanceNuM', 'DistanceNuSTD', 'DistanceGoM',\n",
    "     'DistanceGoSTD', 'TP', 'FP', 'FN', 'ACC', 'TPR', 'FPR', 'FNR', 'PRECISION', 'F1_SCORE']\n",
    "for col in numeric_cols:  # Iterate over the first level of multi-level columns\n",
    "    cols = [(col, 'mean'), (col, 'min'), (col, 'max'), (col, 'std')]\n",
    "    grouped[(col,\"\")] = grouped.apply(lambda row: format_column(row[cols[0]], row[cols[1]], row[cols[2]], row[cols[3]]), axis=1)\n",
    "    grouped = grouped.drop(columns= cols)\n",
    "\n",
    "grouped.columns = grouped.columns.map(''.join)\n",
    "#grouped = grouped[[\"Data Train\",\"Algorithm\", \"Constraints\",\"Angles\",\t\"ROC AUC Score\",\"Accuracy\",\"Precision\",\t\"Recall\",\"F1-Score\"]]\n",
    "display(grouped.sort_values(by=['Edge Feats', 'Constraints','model_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped[[\"Edge Feats\",\"model_type\",\"Constraints\",\"CosineSimilarityM\",\"VecErrorM\",\"ACC\",\"TPR\",\"FPR\", \"PRECISION\", \"F1_SCORE\"]]\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Algorithm column\n",
    "grouped = grouped.sort_values(by=[\"Edge Feats\",\"model_type\"], ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "grouped['model_type'] = grouped['model_type'].replace({\n",
    "    'GNN_Classifier_NonRecurrent': 'MPNN Non-Recurrent',\n",
    "    'GNN_Classifier_Recurrent': 'MPNN Recurrent'\n",
    "})\n",
    "\n",
    "# Add Angular Features information to Algorithm column\n",
    "grouped['model_type'] = grouped.apply(lambda row: f\"{row['model_type']} {'w/ Angular Features' if 'Angular' in row['Edge Feats'] else 'w/o Angular Features'}\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "grouped = grouped.drop(columns=[\"Edge Feats\"])\n",
    "\n",
    "print(grouped.to_latex())\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
