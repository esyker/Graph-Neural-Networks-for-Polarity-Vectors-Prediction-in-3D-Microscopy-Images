{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes type encodings\n",
    "nodes_type_int_encodings = {\n",
    "    \"nuclei\":0,\n",
    "    \"golgi\":1\n",
    "}\n",
    "\n",
    "reversed_nodes_type_int_encodings = {v: k for k, v in nodes_type_int_encodings.items()}\n",
    "\n",
    "#edges type encodings\n",
    "edges_type_int_encodings = {\n",
    "    \"nuclei-nuclei\":0,\n",
    "    \"golgi-golgi\":1,\n",
    "    \"golgi-nuclei\":2,\n",
    "    \"nuclei-golgi\":3\n",
    "}\n",
    "\n",
    "reversed_edges_type_int_encodings = {v: k for k, v in edges_type_int_encodings.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_csv(gt_vectors_csv: str, column_names=['YN', 'XN', 'YG', 'XG', 'ZN', 'ZG'],\n",
    "                     nuclei_columns=['YN', 'XN', 'ZN'],\n",
    "                     golgi_columns=['YG', 'XG', 'ZG'],\n",
    "                     nodes_type_int_encodings=nodes_type_int_encodings,\n",
    "                    edges_type_int_encodings = edges_type_int_encodings):\n",
    "    if(\"automatic\" not in gt_vectors_csv):\n",
    "        df = pd.read_csv(gt_vectors_csv, delimiter=\",\", header=None)\n",
    "        df.columns = column_names\n",
    "\n",
    "        # Split the DataFrame into two\n",
    "        nuclei_df = df[nuclei_columns].copy().reset_index(drop=True)\n",
    "        nuclei_df[\"node_type\"] = nodes_type_int_encodings['nuclei']\n",
    "        nuclei_df.rename(columns={'YN': 'Y', 'XN': 'X', 'ZN': 'Z'}, inplace=True)  # Rename nuclei columns\n",
    "\n",
    "        golgi_df = df[golgi_columns].copy().reset_index(drop=True)\n",
    "        golgi_df[\"node_type\"] = nodes_type_int_encodings['golgi']\n",
    "        golgi_df.rename(columns={'YG': 'Y', 'XG': 'X', 'ZG': 'Z'}, inplace=True)  # Rename golgi columns\n",
    "\n",
    "        # Set the 'ID'\n",
    "        golgi_df[\"ID\"] = range(len(nuclei_df), len(nuclei_df) + len(golgi_df))\n",
    "        nuclei_df[\"ID\"] = range(len(nuclei_df))\n",
    "\n",
    "        # Concatenate the two DataFrames into 'nodes_df'\n",
    "        nodes_df = pd.concat([nuclei_df, golgi_df]).reset_index(drop=True)\n",
    "        nodes_df[\"X\"] = nodes_df[\"X\"].apply(lambda x: x - 1)\n",
    "        nodes_df[\"Y\"] = nodes_df[\"Y\"].apply(lambda y: y - 1)\n",
    "        nodes_df[\"Z\"] = nodes_df[\"Z\"].apply(lambda z: z - 1)\n",
    "\n",
    "        # Create edges between nuclei and golgi based on nodes in the same line\n",
    "        edges_df = pd.DataFrame({'source': nuclei_df['ID'], 'target': golgi_df['ID']})\n",
    "    else:\n",
    "        df = pd.read_csv(gt_vectors_csv, delimiter=\",\")\n",
    "        df[\"node_type\"] = df[\"node_type\"].apply(lambda x : nodes_type_int_encodings[x])\n",
    "        nodes_df = df.copy()\n",
    "        edges_df = pd.DataFrame(columns=['source', 'target', \"edge_type\"])#empty\n",
    "        \n",
    "    return df, nodes_df, edges_df\n",
    "\n",
    "def concat_csv_from_dir(directory):\n",
    "    # Get a list of all files in the directory\n",
    "    all_files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f)) and f.endswith('.csv')]\n",
    "    \n",
    "    # Read each file into a dataframe and store in a list\n",
    "    dfs = []\n",
    "    for f in all_files:\n",
    "        f_path = os.path.join(directory, f)\n",
    "        raw_df, nodes_df, edges_df = load_df_from_csv(f_path)\n",
    "        dfs.append(nodes_df)\n",
    "    \n",
    "    # Concatenate all dataframes in the list into a single dataframe\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df\n",
    "\n",
    "def plot_statistics(df, fig):\n",
    "    # Plot histograms for each feature\n",
    "    n_cols = len(df.columns)\n",
    "    axes = []\n",
    "    for i, column in enumerate(df.columns):\n",
    "        ax = fig.add_subplot(1, n_cols, i+1)  # 1 row, n_cols columns, position i+1\n",
    "        df[column].hist(bins=30, ax=ax)\n",
    "        ax.set_title(column)\n",
    "        axes.append(ax)\n",
    "    return fig\n",
    "\n",
    "def describe_df(directory, fig):\n",
    "    df = concat_csv_from_dir(directory)\n",
    "    print(df.describe())\n",
    "\n",
    "    df = df[[\"X\", \"Y\", \"Z\"]]\n",
    "    \n",
    "    fig =  plot_statistics(df, fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_dirs = [r'../data/vectors',\n",
    "                r'../data/vectors_automatic_csv',\n",
    "                   r'../data/synthetic_algo_1000_points',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and subplots\n",
    "fig = plt.figure(figsize=(17, 5))\n",
    "fig.suptitle(\"(a) Real Data (Manually Annotated)\", fontsize=16)\n",
    "real_graphs_annotated_directory = vector_dirs[0]\n",
    "real_graph_annotated_fig = describe_df(real_graphs_annotated_directory, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and subplots\n",
    "fig = plt.figure(figsize=(17, 5))\n",
    "fig.suptitle(\"(b)  Real Data (Automatic Segmentation)\", fontsize=16)\n",
    "real_graphs_automatic_directory = vector_dirs[1]\n",
    "real_graphs_automatic_fig = describe_df(real_graphs_automatic_directory, fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and subplots\n",
    "fig = plt.figure(figsize=(17, 5))\n",
    "fig.suptitle( \"(c) Synthetic Data\", fontsize=16)\n",
    "synthetic_graphs_directory = vector_dirs[2]\n",
    "synthetic_graphs_fig = describe_df(synthetic_graphs_directory, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Random Walk\n",
    "\n",
    "def generate_random_walk_1D(number_of_points, dims = 1, n_runs = 1, fig_path = None, step_set = [-1, 0, 1]):\n",
    "    assert number_of_points>1\n",
    "    # Define parameters for the walk\n",
    "    step_n = number_of_points - 1 #number of points-1 because it doesn't count the origin\n",
    "    origin = np.zeros((1,dims))\n",
    "    # Simulate steps in 1D\n",
    "    step_shape = (step_n,dims)\n",
    "    steps = np.random.choice(a=step_set, size=step_shape)\n",
    "    path = np.concatenate([origin, steps]).cumsum(0)\n",
    "    return path\n",
    "    \n",
    "def plot_1D_path(path):\n",
    "    number_of_points = len(path)\n",
    "    step_n = number_of_points - 1\n",
    "    start = path[:1]\n",
    "    stop = path[-1:]\n",
    "    # Plot the path\n",
    "    fig = plt.figure(figsize=(3,1),dpi=200)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(np.arange(step_n+1), path, c=\"blue\",alpha=0.25,s=0.05);\n",
    "    ax.plot(path,c=\"blue\",alpha=0.5,lw=0.5,ls=\"-\",);\n",
    "    ax.plot(0, start, c=\"red\", marker=\"+\")\n",
    "    ax.plot(step_n, stop, c=\"black\", marker=\"o\")\n",
    "    plt.title(\"1D Random Walk\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig\n",
    "\n",
    "random_walk_1D = generate_random_walk_1D(100)\n",
    "random_walk_1D_fig = plot_1D_path(random_walk_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Random Walk\n",
    "\n",
    "def generate_random_walk_2D(number_of_points, dims = 2, n_runs = 1, fig_path = None, step_set = [-1, 0 ,1]):\n",
    "    \"\"\"\n",
    "    :param number_of_points: number of points in the random walk\n",
    "    :param dims: number of dimensions of the points\n",
    "    :param number_of_points: number of points in the random walk\n",
    "    :param fig_path: path to save the figure to\n",
    "    :return path: random walk np.array\n",
    "    \"\"\"\n",
    "    assert (number_of_points>1) #is even because it is nuclei-golgi pair\n",
    "    step_n = number_of_points - 1 #number of points-1 because it doesn't count the origin\n",
    "\n",
    "    runs = np.arange(n_runs)\n",
    "    step_shape = (step_n,dims)\n",
    "\n",
    "    origin = np.zeros((1,dims))\n",
    "    # Simulate steps in 2D\n",
    "    \n",
    "    steps = np.random.choice(a=step_set, size=step_shape)\n",
    "    path = np.concatenate([origin, steps]).cumsum(0)\n",
    "    return path\n",
    "\n",
    "def plot_2D_path(path):\n",
    "    start = path[:1]\n",
    "    stop = path[-1:]\n",
    "    # Plot the path\n",
    "    fig = plt.figure(figsize=(3,1),dpi=200)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(path[:,0], path[:,1],c=\"blue\",alpha=0.25,s=0.05);\n",
    "    ax.plot(path[:,0], path[:,1],c=\"blue\",alpha=0.5,lw=0.25,ls=\"-\");\n",
    "    ax.plot(start[:,0], start[:,1],c=\"red\", marker=\"+\")\n",
    "    ax.plot(stop[:,0], stop[:,1],c=\"black\", marker=\"o\")\n",
    "    plt.title(\"2D Random Walk\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    return fig\n",
    "\n",
    "random_walk_2D = generate_random_walk_2D(100)\n",
    "random_walk_2D_fig = plot_2D_path(random_walk_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D Randonm Walk\n",
    "\n",
    "def generate_random_walk_3D(number_of_points, dims = 3, n_runs = 1, fig_path = None):\n",
    "    \"\"\"\n",
    "    :param number_of_points: number of points in the random walk\n",
    "    :param dims: number of dimensions of the points\n",
    "    :param number_of_points: number of points in the random walk\n",
    "    :param fig_path: path to save the figure to\n",
    "    :return path: random walk np.array\n",
    "    \"\"\"\n",
    "    assert (number_of_points>1) #is even because it is nuclei-golgi pair\n",
    "    step_n = number_of_points - 1 #number of points-1 because it doesn't count the origin\n",
    "\n",
    "    step_set = [-1, 0 ,1]\n",
    "    runs = np.arange(n_runs)\n",
    "    step_shape = (step_n,dims)\n",
    "\n",
    "    # Simulate steps in 3D\n",
    "    origin = np.random.randint(low=-10,high=10,size=(1,dims))\n",
    "    steps = np.random.choice(a=step_set, size=step_shape)\n",
    "    path = np.concatenate([origin, steps]).cumsum(0)\n",
    "    \n",
    "    return path\n",
    "\n",
    "def plot_3D_path(path, nuclei_color=\"red\", golgi_color=\"green\"):\n",
    "    # Create a figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=250)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.grid(False)\n",
    "    ax.set_xlabel(\"X\")\n",
    "    ax.set_ylabel(\"Y\")\n",
    "    ax.set_zlabel(\"Z\", labelpad=0, fontsize=12, x=0.95, y=0.9)\n",
    "\n",
    "    \n",
    "    # Plot nuclei and golgi points with lines\n",
    "    for i in range(len(path) - 1):\n",
    "        # Determine the linestyle based on even or odd index\n",
    "        linestyle = \"-\"\n",
    "        line_color = \"blue\"  # Default line color for non-dashed lines\n",
    "        if i % 2 == 1:\n",
    "            linestyle = \"--\"\n",
    "            line_color = \"lightblue\"  # Light blue for dashed lines\n",
    "\n",
    "        # Plot points\n",
    "        marker = \"o\" if i % 2 == 0 else \"^\"  # Set markers for nuclei and golgi\n",
    "        ax.scatter3D(path[i, 0], path[i, 1], path[i, 2], c=nuclei_color if i % 2 == 0 else golgi_color, marker=marker, s=30)\n",
    "        ax.plot3D([path[i, 0], path[i + 1, 0]],\n",
    "                  [path[i, 1], path[i + 1, 1]],\n",
    "                  [path[i, 2], path[i + 1, 2]], linestyle, c=line_color, alpha=0.5, lw=1)  # Set line color\n",
    "\n",
    "    # Plot the last point\n",
    "    ax.scatter3D(path[-1, 0], path[-1, 1], path[-1, 2], c=golgi_color, marker=\"^\", s=30)\n",
    "\n",
    "    # Add a manual legend\n",
    "    custom_legend = [\n",
    "        plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=nuclei_color, markersize=8, label=\"Nuclei\"),\n",
    "        plt.Line2D([0], [0], marker=\"^\", color=\"w\", markerfacecolor=golgi_color, markersize=8, label=\"Golgi\"),\n",
    "        plt.Line2D([0], [0], linestyle=\"-\", color=\"blue\", label=\"Nuclei-Golgi Connection\")\n",
    "    ]\n",
    "    ax.legend(handles=custom_legend, loc=\"upper right\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "random_walk_3D = generate_random_walk_3D(100)\n",
    "random_walk_3D_fig = plot_3D_path(random_walk_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate nuclei Golgi path\n",
    "\n",
    "def calculate_golgi_coords(nuclei_i, nuclei_j, proximity_factor, deviation_factor):\n",
    "    difference_vector = np.subtract(nuclei_j, nuclei_i)\n",
    "    \n",
    "    # Introduce a perturbation based on deviation_factor\n",
    "    perturbation = np.random.uniform(-deviation_factor, deviation_factor, size=difference_vector.shape)\n",
    "    \n",
    "    return np.add(nuclei_i, (difference_vector + perturbation) * proximity_factor)\n",
    "\n",
    "# Nuclei are a 3D random walk, Golgi are in the direction of the next nuclei and near it\n",
    "def generate_nuclei_golgi_3D_path(number_of_points, proximity_factor_range=[0.15, 0.3], deviation_factor_range=[0.05, 0.2], generation_type=\"random_walk_2D_z_normal_distribution\"):\n",
    "    assert number_of_points % 2 == 0\n",
    "\n",
    "    if generation_type == \"random_walk_3D\":\n",
    "        nuclei_path_3D = generate_random_walk_3D(int(number_of_points / 2) + 1, dims=3, n_runs=1, fig_path=None)\n",
    "    elif generation_type == \"random_walk_2D_z_normal_distribution\":\n",
    "        nuclei_path_2D = generate_random_walk_2D(int(number_of_points / 2) + 1, dims=2, n_runs=1, fig_path=None)\n",
    "        z_dimension_path = np.random.normal(0, 1, int(number_of_points / 2) + 1).reshape(int(number_of_points / 2) + 1, 1)\n",
    "        nuclei_path_3D = np.hstack((nuclei_path_2D, z_dimension_path))\n",
    "    elif generation_type == \"random_walk_1D_y_fixed_z_normal_distribution\":\n",
    "        nuclei_path_1D = generate_random_walk_1D(int(number_of_points / 2) + 1, dims = 1, n_runs = 1, fig_path = None)\n",
    "        y_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        z_dimension_path = np.random.normal(0, 1, int(number_of_points / 2) + 1).reshape(int(number_of_points / 2) + 1, 1)\n",
    "        nuclei_path_3D = np.hstack((nuclei_path_1D, y_dimension_path, z_dimension_path))\n",
    "    elif generation_type == \"random_walk_1D_y_fixed_z_fixed\":\n",
    "        nuclei_path_1D_x = generate_random_walk_1D(int(number_of_points / 2) + 1, dims = 1, n_runs = 1, fig_path = None)\n",
    "        y_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        z_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        nuclei_path_3D = np.hstack((nuclei_path_1D_x, y_dimension_path, z_dimension_path))\n",
    "    elif generation_type==\"lin_1D_y_random_walk_z_fixed\":\n",
    "        nuclei_path_1D_x = np.expand_dims(np.linspace(0, number_of_points, num = int(number_of_points / 2) + 1), axis = 1)\n",
    "        y_dimension_path = generate_random_walk_1D(int(number_of_points / 2) + 1, dims = 1, n_runs = 1, fig_path = None)\n",
    "        z_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        nuclei_path_3D = np.hstack((nuclei_path_1D_x, y_dimension_path, z_dimension_path))\n",
    "    elif generation_type==\"lin_1D_y_fixed_z_fixed\":\n",
    "        nuclei_path_1D_x = np.expand_dims(np.linspace(0, number_of_points, num = int(number_of_points / 2) + 1), axis = 1)\n",
    "        y_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        z_dimension_path = np.zeros((int(number_of_points / 2) + 1, 1))\n",
    "        nuclei_path_3D = np.hstack((nuclei_path_1D_x, y_dimension_path, z_dimension_path))\n",
    "        \n",
    "    # Create the final path\n",
    "    path_3D = [0] * number_of_points\n",
    "\n",
    "    # Fill the nuclei first\n",
    "    for i in range(0, len(path_3D), 2):\n",
    "        if (i % 2 == 0):\n",
    "            path_3D[i] = nuclei_path_3D[int(i / 2)]\n",
    "\n",
    "    # Fill the golgi\n",
    "    for i in range(1, len(path_3D), 2):\n",
    "        if (i % 2 != 0):\n",
    "            nuclei_i_pos = int(i / 2)\n",
    "            nuclei_j_pos = int(i / 2) + 1\n",
    "            nuclei_i = nuclei_path_3D[nuclei_i_pos]\n",
    "            nuclei_j = nuclei_path_3D[nuclei_j_pos]\n",
    "            \n",
    "            # Randomly choose proximity_factor and deviation_factor within specified ranges\n",
    "            proximity_factor = np.random.uniform(proximity_factor_range[0], proximity_factor_range[1])\n",
    "            deviation_factor = np.random.uniform(deviation_factor_range[0], deviation_factor_range[1])\n",
    "            \n",
    "            path_3D[i] = calculate_golgi_coords(nuclei_i, nuclei_j, proximity_factor, deviation_factor)\n",
    "\n",
    "    path_3D = np.vstack(path_3D)\n",
    "\n",
    "    return path_3D\n",
    "\n",
    "nuclei_golgi_3D_path = generate_nuclei_golgi_3D_path(100, generation_type=\"random_walk_2D_z_normal_distribution\")\n",
    "nuclei_golgi_3D_path_fig = plot_3D_path(nuclei_golgi_3D_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_csv(array : np.array, csv_path : str, separator = \",\", columns_order=['YN', 'XN', 'YG', 'XG', 'ZN', 'ZG']):\n",
    "    with open(csv_path, 'w') as fp:\n",
    "        for i in range(len(array)):\n",
    "            row_array = array[i]\n",
    "            array_dict = {}\n",
    "            array_dict[\"XN\"], array_dict[\"YN\"], array_dict[\"ZN\"], array_dict[\"XG\"], array_dict[\"YG\"], array_dict[\"ZG\"] = row_array[0], row_array[1], row_array[2], row_array[3], row_array[4], row_array[5]\n",
    "            new_array = [array_dict[col] for col in columns_order]\n",
    "            row = separator.join(str(v) for v in new_array)\n",
    "            if(i!=(len(array)-1)):#only write \\n up to the line before the last line\n",
    "                row+=\"\\n\"\n",
    "            fp.write(row)\n",
    "    return\n",
    "\n",
    "def generate_artificial_dataset(output_dir, \n",
    "                                n_samples, number_points_dist = {\"type\":\"constant\", \"count\":150}, \n",
    "                                proximity_factor_range =[0.15, 0.3], deviation_factor_range=[0.05, 0.2],\n",
    "                                generation_type=\"random_walk_2D_z_normal_distribution\"):\n",
    "    \n",
    "    file_name_prefix = \"Crop\";\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        if number_points_dist[\"type\"]==\"normal\":\n",
    "            #i.e. number_points_dist = {\"type\":\"normal\", \"mu\":150,\"sigma\":10, \"min\":80}, generate a number of points according to normal distribution\n",
    "            number_of_points = round(np.random.normal(number_points_dist[\"mu\"], number_points_dist[\"sigma\"], 1)[0])\n",
    "        elif(number_points_dist[\"type\"]==\"constant\"):\n",
    "            #i.e. number_points_dist = {\"type\":\"constant\", \"count\":150}, generate a constant number of points\n",
    "            number_of_points = number_points_dist[\"count\"]\n",
    "\n",
    "        # Make sure number_of_points is even\n",
    "        number_of_points = number_of_points + 1 if number_of_points % 2 != 0 else number_of_points\n",
    "        \n",
    "        new_data_array = generate_nuclei_golgi_3D_path(number_of_points, proximity_factor_range=proximity_factor_range, \n",
    "                                                  deviation_factor_range=deviation_factor_range, \n",
    "                                                  generation_type=generation_type)\n",
    "        \n",
    "        file_name = file_name_prefix+\"_\"+str(i)+\".csv\"\n",
    "        new_data_array = new_data_array.reshape(int(new_data_array.shape[0]/2), int(new_data_array.shape[1]*2))\n",
    "        array_to_csv(new_data_array, os.path.join(output_dir, file_name))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/synthetic_1000_points/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "n_samples = 8\n",
    "generate_artificial_dataset(output_dir, n_samples, number_points_dist = {\"type\":\"constant\", \"count\":1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Artificial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_to_normalize = [\n",
    "    \"../data/synthetic_algo_100_points\",\n",
    "    \"../data/synthetic_algo_200_points\",\n",
    "    \"../data/synthetic_algo_300_points\",\n",
    "    \"../data/synthetic_algo_400_points\",\n",
    "    \"../data/synthetic_algo_500_points\",\n",
    "    \"../data/synthetic_algo_600_points\",\n",
    "    \"../data/synthetic_algo_700_points\",\n",
    "    \"../data/synthetic_algo_800_points\",\n",
    "    \"../data/synthetic_algo_900_points\",\n",
    "    \"../data/synthetic_algo_1000_points\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_normalize(df, max_values):\n",
    "    return (df-0) / max_values\n",
    "\n",
    "for folder_path in dfs_to_normalize:\n",
    "    csv_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # List CSV files in the folder\n",
    "    dfs = [pd.read_csv(f, delimiter=\",\", header=None) for f in csv_files]\n",
    "\n",
    "    df_concat = pd.concat(dfs).reset_index(drop=True)\n",
    "    max_values = df_concat.abs().max()\n",
    "    \n",
    "    output_folder = folder_path+\"_normalized\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through CSV files again to apply min-max normalization and save\n",
    "    for csv_file in csv_files:\n",
    "        # Read CSV file\n",
    "        df = pd.read_csv(csv_file, delimiter=\",\", header=None)\n",
    "        \n",
    "        # Apply min-max normalization\n",
    "        df_normalized = minmax_normalize(df, max_values)\n",
    "        \n",
    "        # Write normalized DataFrame to a new CSV file\n",
    "        output_file = os.path.join(folder_path+\"_normalized\", os.path.basename(csv_file))\n",
    "        df_normalized.to_csv(output_file, index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
